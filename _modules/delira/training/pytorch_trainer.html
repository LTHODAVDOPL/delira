

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>delira.training.pytorch_trainer &mdash; delira 0.3.0 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../../../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../../../_static/jquery.js"></script>
        <script type="text/javascript" src="../../../_static/underscore.js"></script>
        <script type="text/javascript" src="../../../_static/doctools.js"></script>
        <script type="text/javascript" src="../../../_static/language_data.js"></script>
    
    <script type="text/javascript" src="../../../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/graphviz.css" type="text/css" />
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../../index.html">
          

          
            
            <img src="../../../_static/delira.svg" class="logo" alt="Logo"/>
          
          </a>

          
            
            
              <div class="version">
                0.3.0
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../getting_started.html">Getting started</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../getting_started.html#backends">Backends</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../getting_started.html#installation">Installation</a></li>
</ul>
</li>
</ul>
<p class="caption"><span class="caption-text">Tutorials:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorial_delira.html">Delira Introduction</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorial_delira.html#loading-data">Loading Data</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorial_delira.html#the-dataset">The Dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorial_delira.html#the-dataloader">The Dataloader</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorial_delira.html#the-datamanager">The Datamanager</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorial_delira.html#sampler">Sampler</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorial_delira.html#models">Models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorial_delira.html#init"><code class="docutils literal notranslate"><span class="pre">__init__</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorial_delira.html#closure"><code class="docutils literal notranslate"><span class="pre">closure</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorial_delira.html#prepare-batch"><code class="docutils literal notranslate"><span class="pre">prepare_batch</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorial_delira.html#abstract-networks-for-specific-backends">Abstract Networks for specific Backends</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorial_delira.html#pytorch">PyTorch</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorial_delira.html#forward"><code class="docutils literal notranslate"><span class="pre">forward</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorial_delira.html#id1"><code class="docutils literal notranslate"><span class="pre">prepare_batch</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorial_delira.html#closure-example"><code class="docutils literal notranslate"><span class="pre">closure</span> <span class="pre">example</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorial_delira.html#other-examples">Other examples</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorial_delira.html#training">Training</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorial_delira.html#parameters">Parameters</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorial_delira.html#trainer">Trainer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorial_delira.html#experiment">Experiment</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorial_delira.html#logging">Logging</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorial_delira.html#multistreamhandler"><code class="docutils literal notranslate"><span class="pre">MultiStreamHandler</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorial_delira.html#logging-with-visdom-the-trixi-loggers">Logging with <code class="docutils literal notranslate"><span class="pre">Visdom</span></code> - The <code class="docutils literal notranslate"><span class="pre">trixi</span></code> Loggers</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorial_delira.html#types-of-visdomhandlers">Types of VisdomHandlers</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorial_delira.html#more-examples">More Examples</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../classification_pytorch.html">Classification with Delira - A very short introduction</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../classification_pytorch.html#logging-and-visualization">Logging and Visualization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../classification_pytorch.html#data-preparation">Data Preparation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../classification_pytorch.html#loading">Loading</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../classification_pytorch.html#augmentation">Augmentation</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../classification_pytorch.html#training">Training</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../classification_pytorch.html#see-also">See Also</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../gan_pytorch.html">Generative Adversarial Nets with Delira - A very short introduction</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../gan_pytorch.html#hyperparameters">HyperParameters</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../gan_pytorch.html#logging-and-visualization">Logging and Visualization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../gan_pytorch.html#data-preparation">Data Preparation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../gan_pytorch.html#loading">Loading</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../gan_pytorch.html#augmentation">Augmentation</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../gan_pytorch.html#training">Training</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../gan_pytorch.html#see-also">See Also</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../segmentation_2d_pytorch.html">Segmentation in 2D using U-Nets with Delira - A very short introduction</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../segmentation_2d_pytorch.html#logging-and-visualization">Logging and Visualization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../segmentation_2d_pytorch.html#data-praparation">Data Praparation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../segmentation_2d_pytorch.html#loading">Loading</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../segmentation_2d_pytorch.html#augmentation">Augmentation</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../segmentation_2d_pytorch.html#training">Training</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../segmentation_2d_pytorch.html#see-also">See Also</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../segmentation_3d_pytorch.html">Segmentation in 3D using U-Nets with Delira - A very short introduction</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../segmentation_3d_pytorch.html#logging-and-visualization">Logging and Visualization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../segmentation_3d_pytorch.html#data-praparation">Data Praparation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../segmentation_3d_pytorch.html#loading">Loading</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../segmentation_3d_pytorch.html#augmentation">Augmentation</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../segmentation_3d_pytorch.html#training">Training</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../segmentation_3d_pytorch.html#see-also">See Also</a></li>
</ul>
</li>
</ul>
<p class="caption"><span class="caption-text">API Documentation:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../_api/_build/modules.html">API Documentation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../_api/_build/delira/delira.html">Delira</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../_api/_build/delira/data_loading/data_loading.html">Data Loading</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../_api/_build/delira/data_loading/arbitrary_data.html">Arbitrary Data</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../_api/_build/delira/data_loading/nii.html">Nii</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../_api/_build/delira/data_loading/sampler.html">Sampler</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../_api/_build/delira/delira.io.html">IO</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_api/_build/delira/logging/logging.html">Logging</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../_api/_build/delira/logging/handlers.html"><span class="hidden-section">MultiStreamHandler</span></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../_api/_build/delira/logging/handlers.html#trixihandler"><span class="hidden-section">TrixiHandler</span></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../_api/_build/delira/models/models.html">Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../_api/_build/delira/models/classification.html">Classification</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../_api/_build/delira/models/gan.html">Generative Adversarial Networks</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../_api/_build/delira/models/segmentation.html">Segmentation</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../_api/_build/delira/training/training.html">Training</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../_api/_build/delira/training/parameters.html">Parameters</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../_api/_build/delira/training/trainer.html">Network Trainer</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../_api/_build/delira/training/experiment.html">Experiment</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../_api/_build/delira/training/callbacks.html">Callbacks</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../_api/_build/delira/training/losses.html">Losses</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../_api/_build/delira/training/utils.html"><span class="hidden-section">AurocMetricPyTorch</span></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../_api/_build/delira/training/utils.html#accurarcymetricpytorch"><span class="hidden-section">AccurarcyMetricPyTorch</span></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../_api/_build/delira/training/utils.html#pytorch-batch-to-numpy"><span class="hidden-section">pytorch_batch_to_numpy</span></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../_api/_build/delira/training/utils.html#pytorch-tensor-to-numpy"><span class="hidden-section">pytorch_tensor_to_numpy</span></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../_api/_build/delira/training/utils.html#float-to-pytorch-tensor"><span class="hidden-section">float_to_pytorch_tensor</span></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../_api/_build/delira/training/utils.html#create-optims-default-pytorch"><span class="hidden-section">create_optims_default_pytorch</span></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../_api/_build/delira/training/utils.html#create-optims-gan-default-pytorch"><span class="hidden-section">create_optims_gan_default_pytorch</span></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../_api/_build/delira/training/utils.html#create-optims-default-tf"><span class="hidden-section">create_optims_default_tf</span></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../_api/_build/delira/delira.utils.html">Utilities</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_api/_build/delira/class_hierarchy.html">Class Hierarchy Diagrams</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/justusschock/delira">GitHub</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">delira</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../index.html">Docs</a> &raquo;</li>
        
          <li><a href="../../index.html">Module code</a> &raquo;</li>
        
      <li>delira.training.pytorch_trainer</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <h1>Source code for delira.training.pytorch_trainer</h1><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">tqdm.auto</span> <span class="k">import</span> <span class="n">tqdm</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="k">import</span> <span class="n">OrderedDict</span>
<span class="kn">from</span> <span class="nn">batchgenerators.dataloading</span> <span class="k">import</span> <span class="n">MultiThreadedAugmenter</span>
<span class="kn">from</span> <span class="nn">.callbacks</span> <span class="k">import</span> <span class="n">AbstractCallback</span>
<span class="kn">from</span> <span class="nn">.abstract_trainer</span> <span class="k">import</span> <span class="n">AbstractNetworkTrainer</span>

<span class="n">logger</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>

<span class="k">if</span> <span class="s2">&quot;torch&quot;</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;DELIRA_BACKEND&quot;</span><span class="p">]:</span>
    <span class="kn">import</span> <span class="nn">torch</span>
    <span class="kn">from</span> <span class="nn">.train_utils</span> <span class="k">import</span> <span class="n">pytorch_batch_to_numpy</span>
    <span class="kn">from</span> <span class="nn">.train_utils</span> <span class="k">import</span> <span class="n">create_optims_default_pytorch</span> <span class="k">as</span> <span class="n">create_optims_default</span>
    <span class="kn">from</span> <span class="nn">..io.torch</span> <span class="k">import</span> <span class="n">load_checkpoint</span><span class="p">,</span> <span class="n">save_checkpoint</span>

<div class="viewcode-block" id="PyTorchNetworkTrainer"><a class="viewcode-back" href="../../../_api/_build/delira/training/trainer.html#delira.training.PyTorchNetworkTrainer">[docs]</a>    <span class="k">class</span> <span class="nc">PyTorchNetworkTrainer</span><span class="p">(</span><span class="n">AbstractNetworkTrainer</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Train and Validate a Network</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        :class:`AbstractNetwork`</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">network</span><span class="p">,</span> <span class="n">save_path</span><span class="p">,</span>
                     <span class="n">criterions</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span> <span class="n">optimizer_cls</span><span class="p">,</span>
                     <span class="n">optimizer_params</span><span class="o">=</span><span class="p">{},</span> <span class="n">metrics</span><span class="o">=</span><span class="p">{},</span> <span class="n">lr_scheduler_cls</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                     <span class="n">lr_scheduler_params</span><span class="o">=</span><span class="p">{},</span> <span class="n">gpu_ids</span><span class="o">=</span><span class="p">[],</span> <span class="n">save_freq</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                     <span class="n">optim_fn</span><span class="o">=</span><span class="n">create_optims_default</span><span class="p">,</span>
                     <span class="n">fold</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[],</span> <span class="n">start_epoch</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">mixed_precision</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                     <span class="n">mixed_precision_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;enable_caching&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
                                             <span class="s2">&quot;verbose&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
                                             <span class="s2">&quot;allow_banned&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">},</span>
                     <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
            <span class="sd">&quot;&quot;&quot;</span>

<span class="sd">            Parameters</span>
<span class="sd">            ----------</span>
<span class="sd">            network : :class:`AbstractPyTorchNetwork`</span>
<span class="sd">                the network to train</span>
<span class="sd">            save_path : str</span>
<span class="sd">                path to save networks to</span>
<span class="sd">            criterions : dict</span>
<span class="sd">                dictionary containing the training criterions</span>
<span class="sd">            optimizer_cls : subclass of torch.optim.Optimizer</span>
<span class="sd">                optimizer class implementing the optimization algorithm of choice</span>
<span class="sd">            optimizer_params : dict</span>
<span class="sd">                keyword arguments passed to optimizer during construction</span>
<span class="sd">            metrics : dict</span>
<span class="sd">                dictionary containing the validation metrics</span>
<span class="sd">            lr_scheduler_cls : Any</span>
<span class="sd">                learning rate schedule class: must implement step() method</span>
<span class="sd">            lr_scheduler_params : dict</span>
<span class="sd">                keyword arguments passed to lr scheduler during construction</span>
<span class="sd">            gpu_ids : list</span>
<span class="sd">                list containing ids of GPUs to use; if empty: use cpu instead</span>
<span class="sd">            save_freq : int</span>
<span class="sd">                integer specifying how often to save the current model&#39;s state.</span>
<span class="sd">                State is saved every state_freq epochs</span>
<span class="sd">            optim_fn : function</span>
<span class="sd">                creates a dictionary containing all necessary optimizers</span>
<span class="sd">            fold : int</span>
<span class="sd">                current cross validation fold (0 per default)</span>
<span class="sd">            callbacks : list</span>
<span class="sd">                initial callbacks to register</span>
<span class="sd">            start_epoch : int</span>
<span class="sd">                epoch to start training at</span>
<span class="sd">            mixed_precision : bool</span>
<span class="sd">                whether to use mixed precision or not (False per default)</span>
<span class="sd">            mixed_precision_kwargs : dict</span>
<span class="sd">                additional keyword arguments for mixed precision</span>
<span class="sd">            **kwargs :</span>
<span class="sd">                additional keyword arguments</span>

<span class="sd">            &quot;&quot;&quot;</span>

            <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">fold</span><span class="p">,</span> <span class="n">callbacks</span><span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">save_path</span> <span class="o">=</span> <span class="n">save_path</span>
            <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isdir</span><span class="p">(</span><span class="n">save_path</span><span class="p">):</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                    <span class="s2">&quot;Save Path already exists. Saved Models may be overwritten&quot;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">save_path</span><span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">criterions</span> <span class="o">=</span> <span class="n">criterions</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">metrics</span> <span class="o">=</span> <span class="n">metrics</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">save_freq</span> <span class="o">=</span> <span class="n">save_freq</span>

            <span class="c1"># Whether or not to stop the training</span>
            <span class="c1"># Used for early stopping</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">stop_training</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">start_epoch</span> <span class="o">=</span> <span class="n">start_epoch</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">_setup</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">optim_fn</span><span class="p">,</span> <span class="n">optimizer_cls</span><span class="p">,</span> <span class="n">optimizer_params</span><span class="p">,</span>
                        <span class="n">lr_scheduler_cls</span><span class="p">,</span> <span class="n">lr_scheduler_params</span><span class="p">,</span> <span class="n">gpu_ids</span><span class="p">,</span>
                        <span class="n">mixed_precision</span><span class="p">,</span> <span class="n">mixed_precision_kwargs</span><span class="p">)</span>

            <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">val</span><span class="p">)</span>

<div class="viewcode-block" id="PyTorchNetworkTrainer._setup"><a class="viewcode-back" href="../../../_api/_build/delira/training/trainer.html#delira.training.PyTorchNetworkTrainer._setup">[docs]</a>        <span class="k">def</span> <span class="nf">_setup</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">network</span><span class="p">,</span> <span class="n">optim_fn</span><span class="p">,</span> <span class="n">optimizer_cls</span><span class="p">,</span> <span class="n">optimizer_params</span><span class="p">,</span>
                   <span class="n">lr_scheduler_cls</span><span class="p">,</span> <span class="n">lr_scheduler_params</span><span class="p">,</span> <span class="n">gpu_ids</span><span class="p">,</span>
                   <span class="n">mixed_precision</span><span class="p">,</span> <span class="n">mixed_precision_kwargs</span><span class="p">):</span>
            <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            Defines the Trainers Setup</span>

<span class="sd">            Parameters</span>
<span class="sd">            ----------</span>
<span class="sd">            network : :class:`AbstractPyTorchNetwork`</span>
<span class="sd">                the network to train</span>
<span class="sd">            optim_fn : function</span>
<span class="sd">                creates a dictionary containing all necessary optimizers</span>
<span class="sd">            optimizer_cls : subclass of torch.optim.Optimizer</span>
<span class="sd">                optimizer class implementing the optimization algorithm of choice</span>
<span class="sd">            optimizer_params : dict</span>
<span class="sd">            lr_scheduler_cls : Any</span>
<span class="sd">                learning rate schedule class: must implement step() method</span>
<span class="sd">            lr_scheduler_params : dict</span>
<span class="sd">                keyword arguments passed to lr scheduler during construction</span>
<span class="sd">            gpu_ids : list</span>
<span class="sd">                list containing ids of GPUs to use; if empty: use cpu instead</span>
<span class="sd">            mixed_precision : bool</span>
<span class="sd">                whether to use mixed precision or not (False per default)</span>
<span class="sd">            mixed_precision_kwargs : dict</span>
<span class="sd">                additional keyword arguments for mixed precision</span>

<span class="sd">            &quot;&quot;&quot;</span>

            <span class="k">try</span><span class="p">:</span>
                <span class="kn">from</span> <span class="nn">apex</span> <span class="k">import</span> <span class="n">amp</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_amp_handle</span> <span class="o">=</span> <span class="n">amp</span><span class="o">.</span><span class="n">init</span><span class="p">(</span><span class="n">mixed_precision</span><span class="p">,</span>
                                            <span class="o">*</span><span class="n">mixed_precision_kwargs</span><span class="p">)</span>
                <span class="n">wrap_fn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_amp_handle</span><span class="o">.</span><span class="n">wrap_optimizer</span>

            <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">mixed_precision</span><span class="p">:</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;Apex was not found found, trying to continue </span><span class="se">\</span>
<span class="s2">                                    in full precision instead&quot;</span><span class="p">)</span>
                <span class="kn">from</span> <span class="nn">..utils.context_managers</span> <span class="k">import</span> <span class="n">DefaultOptimWrapperTorch</span>
                <span class="n">wrap_fn</span> <span class="o">=</span> <span class="n">DefaultOptimWrapperTorch</span>

            <span class="c1"># wrap optimizers by half_precision_optimizer via apex if necessary</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">optimizers</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">wrap_fn</span><span class="p">(</span>
                <span class="n">v</span><span class="p">,</span> <span class="n">num_loss</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">criterions</span><span class="p">))</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span>
                <span class="ow">in</span> <span class="n">optim_fn</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">optimizer_cls</span><span class="p">,</span> <span class="o">**</span><span class="n">optimizer_params</span><span class="p">)</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>

            <span class="c1"># schedulers</span>
            <span class="k">if</span> <span class="n">lr_scheduler_cls</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">optim</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                    <span class="k">if</span> <span class="ow">not</span> <span class="nb">issubclass</span><span class="p">(</span><span class="n">lr_scheduler_cls</span><span class="p">,</span> <span class="n">AbstractCallback</span><span class="p">):</span>
                        <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;lr_scheduler_cls is not a callback.&quot;</span><span class="p">)</span>
                    <span class="c1"># access actual optimizer by calling wrapped optimizer from wrapper</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">register_callback</span><span class="p">(</span><span class="n">lr_scheduler_cls</span><span class="p">(</span><span class="n">optim</span><span class="o">.</span><span class="n">_optimizer</span><span class="p">,</span>
                                                            <span class="o">**</span><span class="n">lr_scheduler_params</span><span class="p">))</span>

            <span class="c1"># Load latest epoch file if available</span>
            <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isdir</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">save_path</span><span class="p">):</span>
                <span class="c1"># check all files in directory starting with &quot;checkpoint&quot; and not</span>
                <span class="c1"># ending with &quot;_best.pth&quot;</span>
                <span class="n">files</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">save_path</span><span class="p">)</span>
                         <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isfile</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">save_path</span><span class="p">,</span> <span class="n">x</span><span class="p">))</span>
                         <span class="ow">and</span> <span class="n">x</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;checkpoint&quot;</span><span class="p">)</span>
                         <span class="ow">and</span> <span class="ow">not</span> <span class="n">x</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">&quot;_best.pth&quot;</span><span class="p">)]</span>

                <span class="c1"># if list is not empty: load previous state</span>
                <span class="k">if</span> <span class="n">files</span><span class="p">:</span>

                    <span class="n">latest_epoch</span> <span class="o">=</span> <span class="nb">max</span><span class="p">([</span><span class="nb">int</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">rsplit</span><span class="p">(</span><span class="s2">&quot;_&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">rsplit</span><span class="p">(</span><span class="s2">&quot;.&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">])</span>
                                        <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">files</span><span class="p">])</span>

                    <span class="n">latest_state_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">save_path</span><span class="p">,</span>
                                                     <span class="s2">&quot;checkpoint_epoch_</span><span class="si">%d</span><span class="s2">.pth&quot;</span>
                                                     <span class="o">%</span> <span class="n">latest_epoch</span><span class="p">)</span>

                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Attempting to load state from previous </span><span class="se">\</span>
<span class="s2">                                training from </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">latest_state_path</span><span class="p">)</span>

                    <span class="k">try</span><span class="p">:</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">update_state</span><span class="p">(</span><span class="n">latest_state_path</span><span class="p">,</span>
                                          <span class="n">weights_only</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
                    <span class="k">except</span> <span class="ne">KeyError</span><span class="p">:</span>
                        <span class="k">try</span><span class="p">:</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">update_state</span><span class="p">(</span><span class="n">latest_state_path</span><span class="p">,</span>
                                              <span class="n">weights_only</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">start_epoch</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span>
                                <span class="n">latest_epoch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">start_epoch</span><span class="p">)</span>

                        <span class="k">except</span> <span class="ne">KeyError</span><span class="p">:</span>
                            <span class="n">logger</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s2">&quot;Previous State could not be loaded, </span><span class="se">\</span>
<span class="s2">                                        although it exists.Training will be </span><span class="se">\</span>
<span class="s2">                                        restarted&quot;</span><span class="p">)</span>

            <span class="c1"># asssign closure and prepare batch from network</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">closure_fn</span> <span class="o">=</span> <span class="n">network</span><span class="o">.</span><span class="n">closure</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_prepare_batch</span> <span class="o">=</span> <span class="n">network</span><span class="o">.</span><span class="n">prepare_batch</span>

            <span class="k">if</span> <span class="n">gpu_ids</span> <span class="ow">and</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">use_gpu</span> <span class="o">=</span> <span class="kc">True</span>
                <span class="k">if</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">gpu_ids</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">device_count</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">):</span>
                    <span class="c1"># use GPU 0 as default input GPU</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">input_device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda:</span><span class="si">%d</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">gpu_ids</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

                    <span class="c1"># Train on multiple GPUs and use GPU 0 as output device</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">module</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">DataParallel</span><span class="p">(</span><span class="n">network</span><span class="o">.</span><span class="n">to</span><span class="p">(</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">input_device</span><span class="p">),</span>
                        <span class="n">device_ids</span><span class="o">=</span><span class="n">gpu_ids</span><span class="p">,</span>
                        <span class="n">output_device</span><span class="o">=</span><span class="n">gpu_ids</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

                    <span class="c1"># use GPU 1 as default output GPU for balanced GPU usage</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">output_device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda:</span><span class="si">%d</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">gpu_ids</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="c1"># use the only available GPU as input device</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">input_device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda:</span><span class="si">%d</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">gpu_ids</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">module</span> <span class="o">=</span> <span class="n">network</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">input_device</span><span class="p">)</span>

                    <span class="c1"># use GPU 0 as output device as output device</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">output_device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda:</span><span class="si">%d</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">gpu_ids</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">use_gpu</span> <span class="o">=</span> <span class="kc">False</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">input_device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">output_device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">module</span> <span class="o">=</span> <span class="n">network</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">input_device</span><span class="p">)</span></div>

<div class="viewcode-block" id="PyTorchNetworkTrainer.train"><a class="viewcode-back" href="../../../_api/_build/delira/training/trainer.html#delira.training.PyTorchNetworkTrainer.train">[docs]</a>        <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">,</span> <span class="n">datamgr_train</span><span class="p">,</span> <span class="n">datamgr_valid</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                  <span class="n">val_score_key</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">val_score_mode</span><span class="o">=</span><span class="s1">&#39;highest&#39;</span><span class="p">):</span>
            <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            train network</span>

<span class="sd">            Parameters</span>
<span class="sd">            ----------</span>
<span class="sd">            num_epochs : int</span>
<span class="sd">                number of epochs to train</span>
<span class="sd">            datamgr_train : BaseDataManager</span>
<span class="sd">                Data Manager to create Batch Generator for training</span>
<span class="sd">            datamgr_valid : BaseDataManager</span>
<span class="sd">                Data Manager to create Batch Generator for validation</span>
<span class="sd">            val_score_key : str</span>
<span class="sd">                Key of validation metric; must be key in self.metrics</span>
<span class="sd">            val_score_mode : str</span>
<span class="sd">                String to specify whether a higher or lower validation score is</span>
<span class="sd">                optimal; must be in [&#39;highest&#39;, &#39;lowest&#39;]</span>

<span class="sd">            Returns</span>
<span class="sd">            -------</span>
<span class="sd">            :class:`AbstractPyTorchNetwork`</span>
<span class="sd">                Best model (if `val_score_key` is not a valid key the model of the</span>
<span class="sd">                last epoch will be returned)</span>

<span class="sd">            &quot;&quot;&quot;</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">_at_training_begin</span><span class="p">()</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>

            <span class="k">if</span> <span class="n">val_score_mode</span> <span class="o">==</span> <span class="s1">&#39;highest&#39;</span><span class="p">:</span>
                <span class="n">best_val_score</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">elif</span> <span class="n">val_score_mode</span> <span class="o">==</span> <span class="s1">&#39;lowest&#39;</span><span class="p">:</span>
                <span class="n">best_val_score</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;inf&#39;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">best_val_score</span> <span class="o">=</span> <span class="kc">None</span>

            <span class="n">curr_val_score</span> <span class="o">=</span> <span class="n">best_val_score</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">save_state</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">save_path</span><span class="p">,</span> <span class="s2">&quot;checkpoint_epoch_0.pth&quot;</span><span class="p">),</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">start_epoch</span><span class="p">)</span>
            <span class="n">metrics_val</span> <span class="o">=</span> <span class="p">{}</span>

            <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">start_epoch</span><span class="p">,</span> <span class="n">num_epochs</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>

                <span class="bp">self</span><span class="o">.</span><span class="n">_at_epoch_begin</span><span class="p">(</span><span class="n">metrics_val</span><span class="p">,</span> <span class="n">val_score_key</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span>
                                     <span class="n">num_epochs</span><span class="p">)</span>

                <span class="n">batch_gen_train</span> <span class="o">=</span> <span class="n">datamgr_train</span><span class="o">.</span><span class="n">get_batchgen</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="n">epoch</span><span class="p">)</span>

                <span class="bp">self</span><span class="o">.</span><span class="n">_train_single_epoch</span><span class="p">(</span><span class="n">batch_gen_train</span><span class="p">,</span> <span class="n">epoch</span><span class="p">)</span>

                <span class="k">if</span> <span class="n">datamgr_valid</span><span class="p">:</span>
                    <span class="c1"># validate with batchsize 1 and 1 augmentation processs to</span>
                    <span class="c1"># avoid dropping of last elements</span>
                    <span class="n">orig_num_aug_processes</span> <span class="o">=</span> <span class="n">datamgr_valid</span><span class="o">.</span><span class="n">n_process_augmentation</span>
                    <span class="n">orig_batch_size</span> <span class="o">=</span> <span class="n">datamgr_valid</span><span class="o">.</span><span class="n">batch_size</span>

                    <span class="n">datamgr_valid</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">1</span>
                    <span class="n">datamgr_valid</span><span class="o">.</span><span class="n">n_process_augmentation</span> <span class="o">=</span> <span class="mi">1</span>

                    <span class="n">pred_val</span><span class="p">,</span> <span class="n">labels_val</span><span class="p">,</span> <span class="n">metrics_val</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span>
                        <span class="n">datamgr_valid</span><span class="o">.</span><span class="n">get_batchgen</span><span class="p">(),</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">orig_batch_size</span><span class="p">)</span>

                    <span class="c1"># reset old values</span>
                    <span class="n">datamgr_valid</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">orig_batch_size</span>
                    <span class="n">datamgr_valid</span><span class="o">.</span><span class="n">n_process_augmentation</span> <span class="o">=</span> <span class="n">orig_num_aug_processes</span>

                    <span class="c1"># ToDO: Move decision, if current model is best to callback</span>
                    <span class="k">if</span> <span class="n">val_score_key</span> <span class="ow">in</span> <span class="n">metrics_val</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                        <span class="n">curr_val_score</span> <span class="o">=</span> <span class="n">metrics_val</span><span class="p">[</span><span class="n">val_score_key</span><span class="p">]</span>
                        <span class="n">is_best</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_better_val_scores</span><span class="p">(</span><span class="n">best_val_score</span><span class="p">,</span>
                                                             <span class="n">curr_val_score</span><span class="p">,</span>
                                                             <span class="n">val_score_mode</span><span class="p">)</span>

                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                            <span class="s2">&quot;Validation score key not in metric dict. &quot;</span>
                            <span class="s2">&quot;Logging metrics but can&#39;t decide which model is best&quot;</span><span class="p">)</span>

                        <span class="n">is_best</span> <span class="o">=</span> <span class="kc">False</span>

                    <span class="k">if</span> <span class="n">is_best</span><span class="p">:</span>
                        <span class="n">best_val_score</span> <span class="o">=</span> <span class="n">curr_val_score</span>
                        <span class="n">tqdm</span><span class="o">.</span><span class="n">write</span><span class="p">(</span>
                            <span class="s1">&#39;Best val score = </span><span class="si">%2.3f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">best_val_score</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">is_best</span> <span class="o">=</span> <span class="kc">False</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">is_best</span> <span class="o">=</span> <span class="kc">False</span>
                    <span class="n">labels_val</span><span class="p">,</span> <span class="n">pred_val</span><span class="p">,</span> <span class="n">metrics_val</span> <span class="o">=</span> <span class="p">{},</span> <span class="p">{},</span> <span class="p">{}</span>

                <span class="bp">self</span><span class="o">.</span><span class="n">_at_epoch_end</span><span class="p">(</span><span class="n">metrics_val</span><span class="p">,</span> <span class="n">val_score_key</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">is_best</span><span class="p">)</span>

                <span class="c1"># stop training (might be caused by early stopping)</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">stop_training</span><span class="p">:</span>
                    <span class="k">break</span>

            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_at_training_end</span><span class="p">()</span></div>

<div class="viewcode-block" id="PyTorchNetworkTrainer._at_training_begin"><a class="viewcode-back" href="../../../_api/_build/delira/training/trainer.html#delira.training.PyTorchNetworkTrainer._at_training_begin">[docs]</a>        <span class="k">def</span> <span class="nf">_at_training_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
            <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            Defines behaviour at beginning of training</span>

<span class="sd">            Parameters</span>
<span class="sd">            ----------</span>
<span class="sd">            *args :</span>
<span class="sd">                positional arguments</span>
<span class="sd">            **kwargs :</span>
<span class="sd">                keyword arguments</span>

<span class="sd">            &quot;&quot;&quot;</span>
            <span class="k">pass</span></div>

<div class="viewcode-block" id="PyTorchNetworkTrainer._at_training_end"><a class="viewcode-back" href="../../../_api/_build/delira/training/trainer.html#delira.training.PyTorchNetworkTrainer._at_training_end">[docs]</a>        <span class="k">def</span> <span class="nf">_at_training_end</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
            <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            Defines Behaviour at end of training: Loads best model if available</span>

<span class="sd">            Returns</span>
<span class="sd">            -------</span>
<span class="sd">            :class:`AbstractPyTorchNetwork`</span>
<span class="sd">                best network</span>

<span class="sd">            &quot;&quot;&quot;</span>
            <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isfile</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">save_path</span><span class="p">,</span> <span class="s1">&#39;checkpoint_best.pth&#39;</span><span class="p">)):</span>

                <span class="c1"># load best model and return it</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">update_state</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">save_path</span><span class="p">,</span>
                                               <span class="s1">&#39;checkpoint_best.pth&#39;</span><span class="p">),</span>
                                  <span class="n">weights_only</span><span class="o">=</span><span class="kc">True</span>
                                  <span class="p">)</span>

            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">module</span></div>

<div class="viewcode-block" id="PyTorchNetworkTrainer._at_epoch_begin"><a class="viewcode-back" href="../../../_api/_build/delira/training/trainer.html#delira.training.PyTorchNetworkTrainer._at_epoch_begin">[docs]</a>        <span class="k">def</span> <span class="nf">_at_epoch_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">metrics_val</span><span class="p">,</span> <span class="n">val_score_key</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">,</span>
                            <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
            <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            Defines behaviour at beginning of each epoch: Executes all callbacks&#39;s</span>
<span class="sd">            `at_epoch_begin` method</span>

<span class="sd">            Parameters</span>
<span class="sd">            ----------</span>
<span class="sd">            metrics_val : dict</span>
<span class="sd">                validation metrics</span>
<span class="sd">            val_score_key : str</span>
<span class="sd">                validation score key</span>
<span class="sd">            epoch : int</span>
<span class="sd">                current epoch</span>
<span class="sd">            num_epochs : int</span>
<span class="sd">                total number of epochs</span>
<span class="sd">            **kwargs :</span>
<span class="sd">                keyword arguments</span>

<span class="sd">            &quot;&quot;&quot;</span>

            <span class="c1"># execute all callbacks</span>
            <span class="k">for</span> <span class="n">cb</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_callbacks</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_update_state</span><span class="p">(</span><span class="n">cb</span><span class="o">.</span><span class="n">at_epoch_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">val_metrics</span><span class="o">=</span><span class="n">metrics_val</span><span class="p">,</span>
                                                     <span class="n">val_score_key</span><span class="o">=</span><span class="n">val_score_key</span><span class="p">,</span>
                                                     <span class="n">curr_epoch</span><span class="o">=</span><span class="n">epoch</span><span class="p">),</span>
                                   <span class="n">weights_only</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></div>

<div class="viewcode-block" id="PyTorchNetworkTrainer._at_epoch_end"><a class="viewcode-back" href="../../../_api/_build/delira/training/trainer.html#delira.training.PyTorchNetworkTrainer._at_epoch_end">[docs]</a>        <span class="k">def</span> <span class="nf">_at_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">metrics_val</span><span class="p">,</span> <span class="n">val_score_key</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">is_best</span><span class="p">,</span>
                          <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
            <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            Defines behaviour at beginning of each epoch: Executes all callbacks&#39;s</span>
<span class="sd">            `at_epoch_end` method and saves current state if necessary</span>

<span class="sd">            Parameters</span>
<span class="sd">            ----------</span>
<span class="sd">            metrics_val : dict</span>
<span class="sd">                validation metrics</span>
<span class="sd">            val_score_key : str</span>
<span class="sd">                validation score key</span>
<span class="sd">            epoch : int</span>
<span class="sd">                current epoch</span>
<span class="sd">            num_epochs : int</span>
<span class="sd">                total number of epochs</span>
<span class="sd">            is_best : bool</span>
<span class="sd">                whether current model is best one so far</span>
<span class="sd">            **kwargs :</span>
<span class="sd">                keyword arguments</span>

<span class="sd">            &quot;&quot;&quot;</span>

            <span class="k">for</span> <span class="n">cb</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_callbacks</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_update_state</span><span class="p">(</span><span class="n">cb</span><span class="o">.</span><span class="n">at_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">val_metrics</span><span class="o">=</span><span class="n">metrics_val</span><span class="p">,</span>
                                                   <span class="n">val_score_key</span><span class="o">=</span><span class="n">val_score_key</span><span class="p">,</span>
                                                   <span class="n">curr_epoch</span><span class="o">=</span><span class="n">epoch</span><span class="p">),</span>
                                   <span class="n">weights_only</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">epoch</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">save_freq</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">save_state</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">save_path</span><span class="p">,</span>
                                             <span class="s2">&quot;checkpoint_epoch_</span><span class="si">%d</span><span class="s2">.pth&quot;</span> <span class="o">%</span> <span class="n">epoch</span><span class="p">),</span>
                                <span class="n">epoch</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">is_best</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">save_state</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">save_path</span><span class="p">,</span>
                                             <span class="s2">&quot;checkpoint_best.pth&quot;</span><span class="p">),</span>
                                <span class="n">epoch</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span></div>

<div class="viewcode-block" id="PyTorchNetworkTrainer._train_single_epoch"><a class="viewcode-back" href="../../../_api/_build/delira/training/trainer.html#delira.training.PyTorchNetworkTrainer._train_single_epoch">[docs]</a>        <span class="k">def</span> <span class="nf">_train_single_epoch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batchgen</span><span class="p">:</span> <span class="n">MultiThreadedAugmenter</span><span class="p">,</span> <span class="n">epoch</span><span class="p">):</span>
            <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            Trains the network a single epoch</span>

<span class="sd">            Parameters</span>
<span class="sd">            ----------</span>
<span class="sd">            batchgen : MultiThreadedAugmenter</span>
<span class="sd">                Generator yielding the training batches</span>
<span class="sd">            epoch : int</span>
<span class="sd">                current epoch</span>

<span class="sd">            &quot;&quot;&quot;</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>

            <span class="n">n_batches</span> <span class="o">=</span> <span class="n">batchgen</span><span class="o">.</span><span class="n">generator</span><span class="o">.</span><span class="n">num_batches</span> <span class="o">*</span> <span class="n">batchgen</span><span class="o">.</span><span class="n">num_processes</span>
            <span class="n">pbar</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">enumerate</span><span class="p">(</span><span class="n">batchgen</span><span class="p">),</span> <span class="n">unit</span><span class="o">=</span><span class="s1">&#39; batch&#39;</span><span class="p">,</span> <span class="n">total</span><span class="o">=</span><span class="n">n_batches</span><span class="p">,</span>
                        <span class="n">desc</span><span class="o">=</span><span class="s1">&#39;Epoch </span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">epoch</span><span class="p">)</span>

            <span class="k">for</span> <span class="n">batch_nr</span><span class="p">,</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">pbar</span><span class="p">:</span>

                <span class="n">data_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_prepare_batch</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_device</span><span class="p">,</span>
                                                <span class="bp">self</span><span class="o">.</span><span class="n">output_device</span><span class="p">)</span>

                <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">closure_fn</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="p">,</span> <span class="n">data_dict</span><span class="p">,</span>
                                          <span class="n">optimizers</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">optimizers</span><span class="p">,</span>
                                          <span class="n">criterions</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">criterions</span><span class="p">,</span>
                                          <span class="n">metrics</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">metrics</span><span class="p">,</span>
                                          <span class="n">fold</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">fold</span><span class="p">,</span>
                                          <span class="n">batch_nr</span><span class="o">=</span><span class="n">batch_nr</span><span class="p">)</span>

            <span class="n">batchgen</span><span class="o">.</span><span class="n">_finish</span><span class="p">()</span></div>

<div class="viewcode-block" id="PyTorchNetworkTrainer.predict"><a class="viewcode-back" href="../../../_api/_build/delira/training/trainer.html#delira.training.PyTorchNetworkTrainer.predict">[docs]</a>        <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batchgen</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
            <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            Returns predictions from network for batches from batchgen</span>

<span class="sd">            Parameters</span>
<span class="sd">            ----------</span>
<span class="sd">            batchgen : MultiThreadedAugmenter</span>
<span class="sd">                Generator yielding the batches to predict</span>

<span class="sd">            batch_size : None or int</span>
<span class="sd">                if int: collect batches until batch_size is reached and</span>
<span class="sd">                forward them together</span>

<span class="sd">            Returns</span>
<span class="sd">            -------</span>
<span class="sd">            np.ndarray</span>
<span class="sd">                predictions from batches</span>
<span class="sd">            list of np.ndarray</span>
<span class="sd">                labels from batches</span>
<span class="sd">            dict</span>
<span class="sd">                dictionary containing the mean validation metrics and</span>
<span class="sd">                the mean loss values</span>

<span class="sd">            &quot;&quot;&quot;</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

            <span class="n">outputs_all</span><span class="p">,</span> <span class="n">labels_all</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
            <span class="n">metric_mean_vals</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="n">loss_mean_vals</span> <span class="o">=</span> <span class="p">{}</span>

            <span class="n">n_batches</span> <span class="o">=</span> <span class="n">batchgen</span><span class="o">.</span><span class="n">generator</span><span class="o">.</span><span class="n">num_batches</span> <span class="o">*</span> <span class="n">batchgen</span><span class="o">.</span><span class="n">num_processes</span>

            <span class="n">pbar</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">enumerate</span><span class="p">(</span><span class="n">batchgen</span><span class="p">),</span> <span class="n">unit</span><span class="o">=</span><span class="s1">&#39; sample&#39;</span><span class="p">,</span>
                        <span class="n">total</span><span class="o">=</span><span class="n">n_batches</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="s1">&#39;Test&#39;</span><span class="p">)</span>

            <span class="n">orig_batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
            <span class="n">batch_list</span> <span class="o">=</span> <span class="p">[]</span>

            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">pbar</span><span class="p">:</span>

                <span class="k">if</span> <span class="ow">not</span> <span class="n">batch_list</span> <span class="ow">and</span> <span class="p">(</span><span class="n">n_batches</span> <span class="o">-</span> <span class="n">i</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">batch_size</span><span class="p">:</span>
                    <span class="n">batch_size</span> <span class="o">=</span> <span class="n">n_batches</span> <span class="o">-</span> <span class="n">i</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;Set Batchsize down to </span><span class="si">%d</span><span class="s2"> to avoid cutting &quot;</span>
                                 <span class="s2">&quot;of the last batches&quot;</span> <span class="o">%</span> <span class="n">batch_size</span><span class="p">)</span>

                <span class="n">data_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_prepare_batch</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_device</span><span class="p">,</span>
                                                <span class="bp">self</span><span class="o">.</span><span class="n">output_device</span><span class="p">)</span>
                <span class="c1"># queue inputs and labels</span>
                <span class="n">batch_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">data_dict</span><span class="p">)</span>

                <span class="c1"># if queue is full process queue:</span>
                <span class="k">if</span> <span class="n">batch_size</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch_list</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">batch_size</span><span class="p">:</span>

                    <span class="n">batch_dict</span> <span class="o">=</span> <span class="p">{}</span>
                    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">batch_list</span><span class="p">:</span>
                        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">batch</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                            <span class="k">if</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">batch_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                                <span class="n">batch_dict</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">val</span><span class="p">)</span>
                            <span class="k">else</span><span class="p">:</span>
                                <span class="n">batch_dict</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">val</span><span class="p">]</span>

                    <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">val_list</span> <span class="ow">in</span> <span class="n">batch_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                        <span class="n">batch_dict</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">val_list</span><span class="p">)</span>

                    <span class="n">met_vals</span><span class="p">,</span> <span class="n">loss_vals</span><span class="p">,</span> <span class="n">preds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">closure_fn</span><span class="p">(</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="p">,</span> <span class="n">batch_dict</span><span class="p">,</span>
                        <span class="n">optimizers</span><span class="o">=</span><span class="p">{},</span>
                        <span class="n">criterions</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">criterions</span><span class="p">,</span>
                        <span class="n">metrics</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">metrics</span><span class="p">,</span>
                        <span class="n">fold</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">fold</span><span class="p">)</span>

                    <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">met_vals</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>

                        <span class="k">if</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">metric_mean_vals</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                            <span class="n">metric_mean_vals</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">+=</span> <span class="n">val</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="n">metric_mean_vals</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">val</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>

                    <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">loss_vals</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>

                        <span class="k">if</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">loss_mean_vals</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                            <span class="n">loss_mean_vals</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">+=</span> <span class="n">val</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="n">loss_mean_vals</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">val</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>

                    <span class="n">outputs_all</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                        <span class="p">[</span><span class="n">pytorch_batch_to_numpy</span><span class="p">(</span><span class="n">tmp</span><span class="p">)</span> <span class="k">for</span> <span class="n">tmp</span> <span class="ow">in</span> <span class="n">preds</span><span class="p">])</span>

                    <span class="n">label_dict</span> <span class="o">=</span> <span class="p">{}</span>

                    <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">batch_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                        <span class="k">if</span> <span class="s2">&quot;data&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">key</span> <span class="ow">and</span> <span class="s2">&quot;img&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">key</span><span class="p">:</span>
                            <span class="n">label_dict</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">pytorch_batch_to_numpy</span><span class="p">(</span><span class="n">val</span><span class="p">)</span>

                    <span class="n">labels_all</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">label_dict</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
                                       <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">label_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">())])</span>

                    <span class="n">batch_list</span> <span class="o">=</span> <span class="p">[]</span>

            <span class="n">batchgen</span><span class="o">.</span><span class="n">_finish</span><span class="p">()</span>

            <span class="c1"># transpose labels and outputs to have a list of lists of</span>
            <span class="c1"># labels of same type</span>
            <span class="n">labels_all</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">labels_all</span><span class="p">)</span>
            <span class="n">outputs_all</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">outputs_all</span><span class="p">)</span>

            <span class="n">labels_all</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">(</span><span class="n">_labels</span><span class="p">)</span> <span class="k">for</span> <span class="n">_labels</span> <span class="ow">in</span> <span class="n">labels_all</span><span class="p">]</span>
            <span class="n">outputs_all</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">(</span><span class="n">_outputs</span><span class="p">)</span> <span class="k">for</span> <span class="n">_outputs</span> <span class="ow">in</span> <span class="n">outputs_all</span><span class="p">]</span>

            <span class="c1"># metric_mean_vals contains sums of metrics so far.</span>
            <span class="c1"># Dividing by number of batches to get mean values</span>

            <span class="c1"># if virtual batchsize is given: calculate actual number of batches</span>
            <span class="k">if</span> <span class="n">batch_size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">div</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">n_batches</span> <span class="o">/</span> <span class="n">orig_batch_size</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">div</span> <span class="o">=</span> <span class="n">n_batches</span>

            <span class="n">val_dict</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">metric_mean_vals</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="n">val_dict</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">val</span> <span class="o">/</span> <span class="n">div</span>

            <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">loss_mean_vals</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="n">val_dict</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">val</span> <span class="o">/</span> <span class="n">div</span>

            <span class="k">return</span> <span class="n">outputs_all</span><span class="p">,</span> <span class="n">labels_all</span><span class="p">,</span> <span class="n">val_dict</span></div>

<div class="viewcode-block" id="PyTorchNetworkTrainer.save_state"><a class="viewcode-back" href="../../../_api/_build/delira/training/trainer.html#delira.training.PyTorchNetworkTrainer.save_state">[docs]</a>        <span class="k">def</span> <span class="nf">save_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">file_name</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">weights_only</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
            <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            saves the current state via :func:`delira.io.torch.save_checkpoint`</span>

<span class="sd">            Parameters</span>
<span class="sd">            ----------</span>
<span class="sd">            file_name : str</span>
<span class="sd">                filename to save the state to</span>
<span class="sd">            epoch : int</span>
<span class="sd">                current epoch (will be saved for mapping back)</span>
<span class="sd">            weights_only : bool</span>
<span class="sd">                whether to store only weights (default: False)</span>
<span class="sd">            *args :</span>
<span class="sd">                positional arguments</span>
<span class="sd">            **kwargs :</span>
<span class="sd">                keyword arguments</span>

<span class="sd">            &quot;&quot;&quot;</span>
            <span class="n">save_checkpoint</span><span class="p">(</span><span class="n">file_name</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizers</span><span class="p">,</span> <span class="n">weights_only</span><span class="p">,</span>
                            <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>

<div class="viewcode-block" id="PyTorchNetworkTrainer.load_state"><a class="viewcode-back" href="../../../_api/_build/delira/training/trainer.html#delira.training.PyTorchNetworkTrainer.load_state">[docs]</a>        <span class="nd">@staticmethod</span>
        <span class="k">def</span> <span class="nf">load_state</span><span class="p">(</span><span class="n">file_name</span><span class="p">,</span> <span class="n">weights_only</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
            <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            Loads the new state from file via :func:`delira.io.torch.load_checkpoint`</span>

<span class="sd">            Parameters</span>
<span class="sd">            ----------</span>
<span class="sd">            file_name : str</span>
<span class="sd">                the file to load the state from</span>
<span class="sd">            weights_only : bool</span>
<span class="sd">                whether file contains stored weights only (default: False)</span>
<span class="sd">            **kwargs : keyword arguments</span>

<span class="sd">            Returns</span>
<span class="sd">            -------</span>
<span class="sd">            dict</span>
<span class="sd">                new state</span>

<span class="sd">            &quot;&quot;&quot;</span>
            <span class="k">if</span> <span class="n">weights_only</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">load_checkpoint</span><span class="p">(</span><span class="n">file_name</span><span class="p">,</span> <span class="n">weights_only</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">epoch</span> <span class="o">=</span> <span class="n">load_checkpoint</span><span class="p">(</span><span class="n">file_name</span><span class="p">,</span> <span class="n">weights_only</span><span class="p">,</span>
                                                          <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
                <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;module&quot;</span><span class="p">:</span> <span class="n">model</span><span class="p">,</span> <span class="s2">&quot;optimizers&quot;</span><span class="p">:</span> <span class="n">optimizer</span><span class="p">,</span>
                        <span class="s2">&quot;start_epoch&quot;</span><span class="p">:</span> <span class="n">epoch</span><span class="p">}</span></div>

<div class="viewcode-block" id="PyTorchNetworkTrainer.update_state"><a class="viewcode-back" href="../../../_api/_build/delira/training/trainer.html#delira.training.PyTorchNetworkTrainer.update_state">[docs]</a>        <span class="k">def</span> <span class="nf">update_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">file_name</span><span class="p">,</span> <span class="n">weights_only</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
            <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            Update internal state from a loaded state</span>

<span class="sd">            Parameters</span>
<span class="sd">            ----------</span>
<span class="sd">            file_name : str</span>
<span class="sd">                file containing the new state to load</span>
<span class="sd">            weights_only : bool</span>
<span class="sd">                whether to update only weights or notS</span>
<span class="sd">            *args :</span>
<span class="sd">                positional arguments</span>
<span class="sd">            **kwargs :</span>
<span class="sd">                keyword arguments</span>

<span class="sd">            Returns</span>
<span class="sd">            -------</span>
<span class="sd">            :class:`AbstractNetworkTrainer`</span>
<span class="sd">                the trainer with a modified state</span>

<span class="sd">            &quot;&quot;&quot;</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_update_state</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">load_state</span><span class="p">(</span><span class="n">file_name</span><span class="p">,</span> <span class="n">weights_only</span><span class="p">,</span>
                                               <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">),</span> <span class="n">weights_only</span><span class="p">)</span></div>

<div class="viewcode-block" id="PyTorchNetworkTrainer._update_state"><a class="viewcode-back" href="../../../_api/_build/delira/training/trainer.html#delira.training.PyTorchNetworkTrainer._update_state">[docs]</a>        <span class="k">def</span> <span class="nf">_update_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">new_state</span><span class="p">,</span> <span class="n">weights_only</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
            <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            Update the state from a given new state</span>

<span class="sd">            Parameters</span>
<span class="sd">            ----------</span>
<span class="sd">            new_state : dict</span>
<span class="sd">                new state to update internal state from</span>
<span class="sd">            weights_only : bool</span>
<span class="sd">                whether to update weights only from statedict or update </span>
<span class="sd">                everything</span>

<span class="sd">            Returns</span>
<span class="sd">            -------</span>
<span class="sd">            :class:`PyTorchNetworkTrainer`</span>
<span class="sd">                the trainer with a modified state</span>

<span class="sd">            # &quot;&quot;&quot;</span>
            <span class="c1"># print(&quot;,&quot;.join(new_state.keys()))</span>

            <span class="k">if</span> <span class="n">weights_only</span><span class="p">:</span>
                <span class="k">if</span> <span class="s2">&quot;model&quot;</span> <span class="ow">in</span> <span class="n">new_state</span><span class="p">:</span>
                    <span class="n">model_state</span> <span class="o">=</span> <span class="n">new_state</span><span class="p">[</span><span class="s2">&quot;model&quot;</span><span class="p">]</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">model_state</span> <span class="o">=</span> <span class="n">new_state</span>

                <span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">model_state</span><span class="p">)</span>

                <span class="k">if</span> <span class="s2">&quot;optimizer&quot;</span> <span class="ow">in</span> <span class="n">new_state</span> <span class="ow">and</span> <span class="n">new_state</span><span class="p">[</span><span class="s2">&quot;optimizer&quot;</span><span class="p">]:</span>
                    <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">optimizers</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span>
                            <span class="n">new_state</span><span class="p">[</span><span class="s2">&quot;optimizer&quot;</span><span class="p">][</span><span class="n">key</span><span class="p">])</span>

                <span class="k">if</span> <span class="s2">&quot;epoch&quot;</span> <span class="ow">in</span> <span class="n">new_state</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">start_epoch</span> <span class="o">=</span> <span class="n">new_state</span><span class="p">[</span><span class="s2">&quot;epoch&quot;</span><span class="p">]</span>

                <span class="k">return</span> <span class="bp">self</span>

            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">_update_state</span><span class="p">(</span><span class="n">new_state</span><span class="p">)</span></div></div>
</pre></div>

           </div>
           
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2019, Justus Schock, Oliver Rippel, Christoph Haarburger

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>