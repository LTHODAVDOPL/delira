

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Delira Introduction &mdash; delira 0.3.3 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script type="text/javascript" src="_static/jquery.js"></script>
        <script type="text/javascript" src="_static/underscore.js"></script>
        <script type="text/javascript" src="_static/doctools.js"></script>
        <script type="text/javascript" src="_static/language_data.js"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/graphviz.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Classification with Delira - A very short introduction" href="classification_pytorch.html" />
    <link rel="prev" title="Getting started" href="getting_started.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html">
          

          
            
            <img src="_static/delira.svg" class="logo" alt="Logo"/>
          
          </a>

          
            
            
              <div class="version">
                0.3.3
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="getting_started.html">Getting started</a><ul>
<li class="toctree-l2"><a class="reference internal" href="getting_started.html#backends">Backends</a></li>
<li class="toctree-l2"><a class="reference internal" href="getting_started.html#installation">Installation</a></li>
</ul>
</li>
</ul>
<p class="caption"><span class="caption-text">Tutorials:</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Delira Introduction</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#loading-data">Loading Data</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#the-dataset">The Dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="#the-dataloader">The Dataloader</a></li>
<li class="toctree-l3"><a class="reference internal" href="#the-datamanager">The Datamanager</a></li>
<li class="toctree-l3"><a class="reference internal" href="#sampler">Sampler</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#models">Models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#init"><code class="docutils literal notranslate"><span class="pre">__init__</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#closure"><code class="docutils literal notranslate"><span class="pre">closure</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#prepare-batch"><code class="docutils literal notranslate"><span class="pre">prepare_batch</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#abstract-networks-for-specific-backends">Abstract Networks for specific Backends</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#pytorch">PyTorch</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#forward"><code class="docutils literal notranslate"><span class="pre">forward</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#id1"><code class="docutils literal notranslate"><span class="pre">prepare_batch</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#closure-example"><code class="docutils literal notranslate"><span class="pre">closure</span> <span class="pre">example</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#other-examples">Other examples</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#training">Training</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#parameters">Parameters</a></li>
<li class="toctree-l3"><a class="reference internal" href="#trainer">Trainer</a></li>
<li class="toctree-l3"><a class="reference internal" href="#experiment">Experiment</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#logging">Logging</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#multistreamhandler"><code class="docutils literal notranslate"><span class="pre">MultiStreamHandler</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#logging-with-visdom-the-trixi-loggers">Logging with <code class="docutils literal notranslate"><span class="pre">Visdom</span></code> - The <code class="docutils literal notranslate"><span class="pre">trixi</span></code> Loggers</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#types-of-visdomhandlers">Types of VisdomHandlers</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#more-examples">More Examples</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="classification_pytorch.html">Classification with Delira - A very short introduction</a><ul>
<li class="toctree-l2"><a class="reference internal" href="classification_pytorch.html#logging-and-visualization">Logging and Visualization</a></li>
<li class="toctree-l2"><a class="reference internal" href="classification_pytorch.html#data-preparation">Data Preparation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="classification_pytorch.html#loading">Loading</a></li>
<li class="toctree-l3"><a class="reference internal" href="classification_pytorch.html#augmentation">Augmentation</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="classification_pytorch.html#training">Training</a></li>
<li class="toctree-l2"><a class="reference internal" href="classification_pytorch.html#see-also">See Also</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="gan_pytorch.html">Generative Adversarial Nets with Delira - A very short introduction</a><ul>
<li class="toctree-l2"><a class="reference internal" href="gan_pytorch.html#hyperparameters">HyperParameters</a></li>
<li class="toctree-l2"><a class="reference internal" href="gan_pytorch.html#logging-and-visualization">Logging and Visualization</a></li>
<li class="toctree-l2"><a class="reference internal" href="gan_pytorch.html#data-preparation">Data Preparation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="gan_pytorch.html#loading">Loading</a></li>
<li class="toctree-l3"><a class="reference internal" href="gan_pytorch.html#augmentation">Augmentation</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="gan_pytorch.html#training">Training</a></li>
<li class="toctree-l2"><a class="reference internal" href="gan_pytorch.html#see-also">See Also</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="segmentation_2d_pytorch.html">Segmentation in 2D using U-Nets with Delira - A very short introduction</a><ul>
<li class="toctree-l2"><a class="reference internal" href="segmentation_2d_pytorch.html#logging-and-visualization">Logging and Visualization</a></li>
<li class="toctree-l2"><a class="reference internal" href="segmentation_2d_pytorch.html#data-praparation">Data Praparation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="segmentation_2d_pytorch.html#loading">Loading</a></li>
<li class="toctree-l3"><a class="reference internal" href="segmentation_2d_pytorch.html#augmentation">Augmentation</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="segmentation_2d_pytorch.html#training">Training</a></li>
<li class="toctree-l2"><a class="reference internal" href="segmentation_2d_pytorch.html#see-also">See Also</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="segmentation_3d_pytorch.html">Segmentation in 3D using U-Nets with Delira - A very short introduction</a><ul>
<li class="toctree-l2"><a class="reference internal" href="segmentation_3d_pytorch.html#logging-and-visualization">Logging and Visualization</a></li>
<li class="toctree-l2"><a class="reference internal" href="segmentation_3d_pytorch.html#data-praparation">Data Praparation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="segmentation_3d_pytorch.html#loading">Loading</a></li>
<li class="toctree-l3"><a class="reference internal" href="segmentation_3d_pytorch.html#augmentation">Augmentation</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="segmentation_3d_pytorch.html#training">Training</a></li>
<li class="toctree-l2"><a class="reference internal" href="segmentation_3d_pytorch.html#see-also">See Also</a></li>
</ul>
</li>
</ul>
<p class="caption"><span class="caption-text">API Documentation:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="_api/_build/modules.html">API Documentation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="_api/_build/delira/delira.html">Delira</a><ul>
<li class="toctree-l3"><a class="reference internal" href="_api/_build/delira/data_loading/data_loading.html">Data Loading</a><ul>
<li class="toctree-l4"><a class="reference internal" href="_api/_build/delira/data_loading/arbitrary_data.html">Arbitrary Data</a></li>
<li class="toctree-l4"><a class="reference internal" href="_api/_build/delira/data_loading/nii.html">Nii</a></li>
<li class="toctree-l4"><a class="reference internal" href="_api/_build/delira/data_loading/sampler.html">Sampler</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="_api/_build/delira/delira.io.html">IO</a></li>
<li class="toctree-l3"><a class="reference internal" href="_api/_build/delira/logging/logging.html">Logging</a><ul>
<li class="toctree-l4"><a class="reference internal" href="_api/_build/delira/logging/handlers.html"><span class="hidden-section">MultiStreamHandler</span></a></li>
<li class="toctree-l4"><a class="reference internal" href="_api/_build/delira/logging/handlers.html#trixihandler"><span class="hidden-section">TrixiHandler</span></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="_api/_build/delira/models/models.html">Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="_api/_build/delira/models/classification.html">Classification</a></li>
<li class="toctree-l4"><a class="reference internal" href="_api/_build/delira/models/gan.html">Generative Adversarial Networks</a></li>
<li class="toctree-l4"><a class="reference internal" href="_api/_build/delira/models/segmentation.html">Segmentation</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="_api/_build/delira/training/training.html">Training</a><ul>
<li class="toctree-l4"><a class="reference internal" href="_api/_build/delira/training/parameters.html">Parameters</a></li>
<li class="toctree-l4"><a class="reference internal" href="_api/_build/delira/training/trainer.html">Network Trainer</a></li>
<li class="toctree-l4"><a class="reference internal" href="_api/_build/delira/training/experiment.html">Experiment</a></li>
<li class="toctree-l4"><a class="reference internal" href="_api/_build/delira/training/callbacks.html">Callbacks</a></li>
<li class="toctree-l4"><a class="reference internal" href="_api/_build/delira/training/losses.html">Losses</a></li>
<li class="toctree-l4"><a class="reference internal" href="_api/_build/delira/training/utils.html"><span class="hidden-section">AurocMetricPyTorch</span></a></li>
<li class="toctree-l4"><a class="reference internal" href="_api/_build/delira/training/utils.html#accurarcymetricpytorch"><span class="hidden-section">AccurarcyMetricPyTorch</span></a></li>
<li class="toctree-l4"><a class="reference internal" href="_api/_build/delira/training/utils.html#pytorch-batch-to-numpy"><span class="hidden-section">pytorch_batch_to_numpy</span></a></li>
<li class="toctree-l4"><a class="reference internal" href="_api/_build/delira/training/utils.html#pytorch-tensor-to-numpy"><span class="hidden-section">pytorch_tensor_to_numpy</span></a></li>
<li class="toctree-l4"><a class="reference internal" href="_api/_build/delira/training/utils.html#float-to-pytorch-tensor"><span class="hidden-section">float_to_pytorch_tensor</span></a></li>
<li class="toctree-l4"><a class="reference internal" href="_api/_build/delira/training/utils.html#create-optims-default-pytorch"><span class="hidden-section">create_optims_default_pytorch</span></a></li>
<li class="toctree-l4"><a class="reference internal" href="_api/_build/delira/training/utils.html#create-optims-gan-default-pytorch"><span class="hidden-section">create_optims_gan_default_pytorch</span></a></li>
<li class="toctree-l4"><a class="reference internal" href="_api/_build/delira/training/utils.html#create-optims-default-tf"><span class="hidden-section">create_optims_default_tf</span></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="_api/_build/delira/delira.utils.html">Utilities</a></li>
<li class="toctree-l3"><a class="reference internal" href="_api/_build/delira/class_hierarchy.html">Class Hierarchy Diagrams</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/justusschock/delira">GitHub</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">delira</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li>Delira Introduction</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/tutorial_delira.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="delira-introduction">
<h1>Delira Introduction<a class="headerlink" href="#delira-introduction" title="Permalink to this headline">¶</a></h1>
<p>Authors: Justus Schock, Christoph Haarburger</p>
<div class="section" id="loading-data">
<h2>Loading Data<a class="headerlink" href="#loading-data" title="Permalink to this headline">¶</a></h2>
<p>To train your network you first need to load your training data (and
probably also your validation data). This chapter will therefore deal
with <code class="docutils literal notranslate"><span class="pre">delira</span></code>’s capabilities to load your data (and apply some
augmentation).</p>
<div class="section" id="the-dataset">
<h3>The Dataset<a class="headerlink" href="#the-dataset" title="Permalink to this headline">¶</a></h3>
<p>There are mainly two ways to load your data: Lazy or non-lazy. Loading
in a lazy way means that you load the data just in time and keep the
used memory to a bare minimum. This has, however, the disadvantage that
your loading function could be a bottleneck since all postponed
operations may have to wait until the needed data samples are loaded. In
a no-lazy way, one would preload all data to RAM before starting any
other operations. This has the advantage that there cannot be a loading
bottleneck during latter operations. This advantage comes at cost of a
higher memory usage and a (possibly) huge latency at the beginning of
each experiment. Both ways to load your data are implemented in
<code class="docutils literal notranslate"><span class="pre">delira</span></code> and they are named <code class="docutils literal notranslate"><span class="pre">BaseLazyDataset</span></code>and
<code class="docutils literal notranslate"><span class="pre">BaseCacheDataset</span></code>. In the following steps you will only see the
<code class="docutils literal notranslate"><span class="pre">BaseLazyDataset</span></code> since exchanging them is trivial. All Datasets
(including the ones you might want to create yourself later) must be
derived of <code class="docutils literal notranslate"><span class="pre">delira.data_loading.AbstractDataset</span></code> to ensure a minimum
common API.</p>
<p>The dataset’s <code class="docutils literal notranslate"><span class="pre">__init__</span></code> has the following signature:</p>
<div class="code python highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data_path</span><span class="p">,</span> <span class="n">load_fn</span><span class="p">,</span> <span class="n">img_extensions</span><span class="p">,</span> <span class="n">gt_extensions</span><span class="p">,</span>
                 <span class="o">**</span><span class="n">load_kwargs</span><span class="p">):</span>
</pre></div>
</div>
<p>This means, you have to pass the path to the directory containing your
data (<code class="docutils literal notranslate"><span class="pre">data_path</span></code>), a function to load a single sample of your data
(<code class="docutils literal notranslate"><span class="pre">load_fn</span></code>), the file extensions for valid images (<code class="docutils literal notranslate"><span class="pre">img_extensions</span></code>)
and the extensions for valid groundtruth files (<code class="docutils literal notranslate"><span class="pre">gt_files</span></code>). The
defined extensions are used to index all data files in the given
<code class="docutils literal notranslate"><span class="pre">data_path</span></code>. To get a single sample of your dataset after creating it,
you can index it like this: <code class="docutils literal notranslate"><span class="pre">dataset[0]</span></code>.</p>
<p>The missing argument <code class="docutils literal notranslate"><span class="pre">**load_kwargs</span></code> accepts an arbitrary amount of
additional keyword arguments which are directly passed to your loading
function.</p>
<p>An example of how loading your data may look like is given below:</p>
<div class="code python highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">delira.data_loading</span> <span class="k">import</span> <span class="n">BaseLazyDataset</span><span class="p">,</span> <span class="n">default_load_fn_2d</span>
<span class="n">dataset_train</span> <span class="o">=</span> <span class="n">BaseLazyDataset</span><span class="p">(</span><span class="s2">&quot;/images/datasets/external/mnist/train&quot;</span><span class="p">,</span>
                                <span class="n">default_load_fn_2d</span><span class="p">,</span> <span class="n">img_extensions</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;.png&quot;</span><span class="p">],</span>
                                <span class="n">gt_extensions</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;.txt&quot;</span><span class="p">],</span> <span class="n">img_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">))</span>
</pre></div>
</div>
<p>In this case all data lying in <code class="docutils literal notranslate"><span class="pre">/images/datasets/external/mnist/train</span></code>
is loaded by <code class="docutils literal notranslate"><span class="pre">default_load_fn_2d</span></code>. The files containing the data must
be PNG-files, while the groundtruth is defined in TXT-files. The
<code class="docutils literal notranslate"><span class="pre">default_load_fn_2d</span></code> needs the additional argument <code class="docutils literal notranslate"><span class="pre">img_shape</span></code> which
is passed as keyword argument via <code class="docutils literal notranslate"><span class="pre">**load_kwargs</span></code>.</p>
<blockquote>
<div><strong>Note:</strong> for reproducability we decided to use some wrapped PyTorch
datasets for this introduction.</div></blockquote>
<p>Now, let’s just initialize our trainset:</p>
<div class="code ipython3 highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">delira.data_loading</span> <span class="k">import</span> <span class="n">TorchvisionClassificationDataset</span>
<span class="n">dataset_train</span> <span class="o">=</span> <span class="n">TorchvisionClassificationDataset</span><span class="p">(</span><span class="s2">&quot;mnist&quot;</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                                 <span class="n">img_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">))</span>
</pre></div>
</div>
<p>Getting a single sample of your dataset with dataset_train[0] will
produce:</p>
<div class="code ipython3 highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">dataset_train</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
<p>which means, that our data is stored in a dictionary containing the keys
<code class="docutils literal notranslate"><span class="pre">data</span></code> and <code class="docutils literal notranslate"><span class="pre">label</span></code>, each of them holding the corresponding numpy
arrays. The dataloading works on <code class="docutils literal notranslate"><span class="pre">numpy</span></code> purely and is thus backend
agnostic. It does not matter in which format or with which library you
load/preprocess your data, but at the end it must be converted to numpy
arrays For validation purposes another dataset could be created with the
test data like this:</p>
<div class="code ipython3 highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">dataset_val</span> <span class="o">=</span> <span class="n">TorchvisionClassificationDataset</span><span class="p">(</span><span class="s2">&quot;mnist&quot;</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                                               <span class="n">img_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="section" id="the-dataloader">
<h3>The Dataloader<a class="headerlink" href="#the-dataloader" title="Permalink to this headline">¶</a></h3>
<p>The Dataloader wraps your dataset to privode the ability to load whole
batches with an abstract interface. To create a dataloader, one would
have to pass the following arguments to it’s <code class="docutils literal notranslate"><span class="pre">__init__</span></code>: the
previously created <code class="docutils literal notranslate"><span class="pre">dataset</span></code>.Additionally, it is possible to pass the
<code class="docutils literal notranslate"><span class="pre">batch_size</span></code> defining the number of samples per batch, the total
number of batches (<code class="docutils literal notranslate"><span class="pre">num_batches</span></code>), which will be the number of samples
in your dataset devided by the batchsize per default, a random
<code class="docutils literal notranslate"><span class="pre">seed</span></code>for always getting the same behaviour of random number
generators and a <code class="docutils literal notranslate"><span class="pre">`sampler</span></code> &lt;&gt;`__ defining your sampling strategy.
This would create a dataloader for your <code class="docutils literal notranslate"><span class="pre">dataset_train</span></code>:</p>
<div class="code ipython3 highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">delira.data_loading</span> <span class="k">import</span> <span class="n">BaseDataLoader</span>

<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">32</span>

<span class="n">loader_train</span> <span class="o">=</span> <span class="n">BaseDataLoader</span><span class="p">(</span><span class="n">dataset_train</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
</pre></div>
</div>
<p>Since the batch_size has been set to 32, the loader will load 32
samples as one batch.</p>
<p>Even though it would be possible to train your network with an instance
of <code class="docutils literal notranslate"><span class="pre">BaseDataLoader</span></code>, <code class="docutils literal notranslate"><span class="pre">malira</span></code> also offers a different approach that
covers multithreaded data loading and augmentation:</p>
</div>
<div class="section" id="the-datamanager">
<h3>The Datamanager<a class="headerlink" href="#the-datamanager" title="Permalink to this headline">¶</a></h3>
<p>The data manager is implemented as
<code class="docutils literal notranslate"><span class="pre">delira.data_loading.BaseDataManager</span></code> and wraps a <code class="docutils literal notranslate"><span class="pre">DataLoader</span></code>. It
also encapsulates augmentations. Having a view on the
<code class="docutils literal notranslate"><span class="pre">BaseDataManager</span></code>’s signature, it becomes obvious that it accepts the
same arguments as the <code class="docutils literal notranslate"><span class="pre">`DataLoader</span></code> &lt;#The-Dataloader&gt;`__. You can
either pass a <code class="docutils literal notranslate"><span class="pre">dataset</span></code> or a combination of path, dataset class and
load function. Additionally, you can pass a custom dataloder class if
necessary and a sampler class to choose a sampling algorithm.</p>
<p>The parameter <code class="docutils literal notranslate"><span class="pre">transforms</span></code> accepts augmentation transformations as
implemented in <code class="docutils literal notranslate"><span class="pre">batchgenerators</span></code>. Augmentation is applied on the fly
using <code class="docutils literal notranslate"><span class="pre">n_process_augmentation</span></code> threads.</p>
<p>All in all the DataManager is the recommended way to generate batches
from your dataset.</p>
<p>The following example shows how to create a data manager instance:</p>
<div class="code ipython3 highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">delira.data_loading</span> <span class="k">import</span> <span class="n">BaseDataManager</span>
<span class="kn">from</span> <span class="nn">batchgenerators.transforms.abstract_transforms</span> <span class="k">import</span> <span class="n">Compose</span>
<span class="kn">from</span> <span class="nn">batchgenerators.transforms.spatial_transforms</span> <span class="k">import</span> <span class="n">MirrorTransform</span>
<span class="kn">from</span> <span class="nn">batchgenerators.transforms.sample_normalization_transforms</span> <span class="k">import</span> <span class="n">MeanStdNormalizationTransform</span>

<span class="n">batchsize</span> <span class="o">=</span> <span class="mi">64</span>
<span class="n">transforms</span> <span class="o">=</span> <span class="n">Compose</span><span class="p">([</span><span class="n">MeanStdNormalizationTransform</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="mi">1</span><span class="o">*</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">std</span><span class="o">=</span><span class="mi">1</span><span class="o">*</span><span class="p">[</span><span class="mi">1</span><span class="p">])])</span>

<span class="n">data_manager_train</span> <span class="o">=</span> <span class="n">BaseDataManager</span><span class="p">(</span><span class="n">dataset_train</span><span class="p">,</span>  <span class="c1"># dataset to use</span>
                                    <span class="n">batchsize</span><span class="p">,</span>  <span class="c1"># batchsize</span>
                                    <span class="n">n_process_augmentation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>  <span class="c1"># number of augmentation processes</span>
                                    <span class="n">transforms</span><span class="o">=</span><span class="n">transforms</span><span class="p">)</span>  <span class="c1"># augmentation transforms</span>
</pre></div>
</div>
<p>The approach to initialize a DataManager from a datapath takes more
arguments since, in opposite to initializaton from dataset, it needs all
the arguments which are necessary to internally create a dataset.</p>
<p>Since we want to validate our model we have to create a second manager
containing our <code class="docutils literal notranslate"><span class="pre">dataset_val</span></code>:</p>
<div class="code ipython3 highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">data_manager_val</span> <span class="o">=</span> <span class="n">BaseDataManager</span><span class="p">(</span><span class="n">dataset_val</span><span class="p">,</span>
                                    <span class="n">batchsize</span><span class="p">,</span>
                                    <span class="n">n_process_augmentation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                                    <span class="n">transforms</span><span class="o">=</span><span class="n">transforms</span><span class="p">)</span>
</pre></div>
</div>
<p>That’s it - we just finished loading our data!</p>
<p>Iterating over a DataManager is possible in simple loops:</p>
<div class="code ipython3 highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">tqdm.auto</span> <span class="k">import</span> <span class="n">tqdm</span> <span class="c1"># utility for progress bars</span>

<span class="c1"># create actual batch generator from DataManager</span>
<span class="n">batchgen</span> <span class="o">=</span> <span class="n">data_manager_val</span><span class="o">.</span><span class="n">get_batchgen</span><span class="p">()</span>

<span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">batchgen</span><span class="p">):</span>
    <span class="k">pass</span> <span class="c1"># here you can access the data of the current batch</span>
</pre></div>
</div>
</div>
<div class="section" id="sampler">
<h3>Sampler<a class="headerlink" href="#sampler" title="Permalink to this headline">¶</a></h3>
<p>In previous section samplers have been already mentioned but not yet
explained. A sampler implements an algorithm how a batch should be
assembled from single samples in a dataset. <code class="docutils literal notranslate"><span class="pre">delira</span></code> provides the
following sampler classes in it’s subpackage
<code class="docutils literal notranslate"><span class="pre">delira.data_loading.sampler</span></code>:</p>
<ul class="simple">
<li><code class="docutils literal notranslate"><span class="pre">AbstractSampler</span></code></li>
<li><code class="docutils literal notranslate"><span class="pre">SequentialSampler</span></code></li>
<li><code class="docutils literal notranslate"><span class="pre">PrevalenceSequentialSampler</span></code></li>
<li><code class="docutils literal notranslate"><span class="pre">RandomSampler</span></code></li>
<li><code class="docutils literal notranslate"><span class="pre">PrevalenceRandomSampler</span></code></li>
<li><code class="docutils literal notranslate"><span class="pre">WeightedRandomSampler</span></code></li>
<li><code class="docutils literal notranslate"><span class="pre">LambdaSampler</span></code></li>
</ul>
<p>The <code class="docutils literal notranslate"><span class="pre">AbstractSampler</span></code> implements no sampling algorithm but defines a
sampling API and thus all custom samplers must inherit from this class.
The <code class="docutils literal notranslate"><span class="pre">Sequential</span></code> sampler builds batches by just iterating over the
samples’ indices in a sequential way. Following this, the
<code class="docutils literal notranslate"><span class="pre">RandomSampler</span></code> builds batches by randomly drawing the samples’
indices with replacement. If the class each sample belongs to is known
for each sample at the beginning, the <code class="docutils literal notranslate"><span class="pre">PrevalenceSequentialSampler</span></code>
and the <code class="docutils literal notranslate"><span class="pre">PrevalenceRandomSampler</span></code> perform a per-class sequential or
random sampling and building each batch with the exactly same number of
samples from each class. The <code class="docutils literal notranslate"><span class="pre">WeightedRandomSampler</span></code>accepts custom
weights to give specific samples a higher probability during random
sampling than others.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">LambdaSampler</span></code> is a wrapper for a custom sampling function, which
can be passed to the wrapper during it’s initialization, to ensure API
conformity.</p>
<p>It can be passed to the DataLoader or DataManager as class (argument
<code class="docutils literal notranslate"><span class="pre">sampler_cls</span></code>) or as instance (argument <code class="docutils literal notranslate"><span class="pre">sampler</span></code>).</p>
</div>
</div>
<div class="section" id="models">
<h2>Models<a class="headerlink" href="#models" title="Permalink to this headline">¶</a></h2>
<p>Since the purpose of this framework is to use machine learning
algorithms, there has to be a way to define them. Defining models is
straight forward. <code class="docutils literal notranslate"><span class="pre">delira</span></code> provides a class
<code class="docutils literal notranslate"><span class="pre">delira.models.AbstractNetwork</span></code>. <em>All models must inherit from this
class</em>.</p>
<p>To inherit this class four functions must be implemented in the
subclass:</p>
<ul class="simple">
<li><code class="docutils literal notranslate"><span class="pre">__init__</span></code></li>
<li><code class="docutils literal notranslate"><span class="pre">closure</span></code></li>
<li><code class="docutils literal notranslate"><span class="pre">prepare_batch</span></code></li>
<li><code class="docutils literal notranslate"><span class="pre">__call__</span></code></li>
</ul>
<div class="section" id="init">
<h3><code class="docutils literal notranslate"><span class="pre">__init__</span></code><a class="headerlink" href="#init" title="Permalink to this headline">¶</a></h3>
<p>The <code class="docutils literal notranslate"><span class="pre">__init__</span></code>function is a classes constructor. In our case it
builds the entire model (maybe using some helper functions). If writing
your own custom model, you have to override this method.</p>
<blockquote>
<div><strong>Note:</strong> If you want the best experience for saving your model and
completely recreating it during the loading process you need to take
care of a few things: * if using <code class="docutils literal notranslate"><span class="pre">torchvision.models</span></code> to build
your model, always import it with
<code class="docutils literal notranslate"><span class="pre">from</span> <span class="pre">torchvision</span> <span class="pre">import</span> <span class="pre">models</span> <span class="pre">as</span> <span class="pre">t_models</span></code> * register all
arguments in your custom <code class="docutils literal notranslate"><span class="pre">__init__</span></code> in the abstract class. A
init_prototype could look like this:</div></blockquote>
<div class="code python highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">n_outputs</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    in_channels: int</span>
<span class="sd">        number of input_channels</span>
<span class="sd">    n_outputs: int</span>
<span class="sd">        number of outputs (usually same as number of classes)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># register params by passing them as kwargs to parent class __init__</span>
    <span class="c1"># only params registered like this will be saved!</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="n">in_channels</span><span class="p">,</span>
                     <span class="n">n_outputs</span><span class="o">=</span><span class="n">n_outputs</span><span class="p">,</span>
                     <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="closure">
<h3><code class="docutils literal notranslate"><span class="pre">closure</span></code><a class="headerlink" href="#closure" title="Permalink to this headline">¶</a></h3>
<p>The <code class="docutils literal notranslate"><span class="pre">closure</span></code>function defines one batch iteration to train the
network. This function is needed for the framework to provide a generic
trainer function which works with all kind of networks and loss
functions.</p>
<p>The closure function must implement all steps from forwarding, over loss
calculation, metric calculation, logging (for which
<code class="docutils literal notranslate"><span class="pre">delira.logging_handlers</span></code> provides some extensions for pythons logging
module), and the actual backpropagation.</p>
<p>It is called with an empty optimizer-dict to evaluate and should thus
work with optional optimizers.</p>
</div>
<div class="section" id="prepare-batch">
<h3><code class="docutils literal notranslate"><span class="pre">prepare_batch</span></code><a class="headerlink" href="#prepare-batch" title="Permalink to this headline">¶</a></h3>
<p>The <code class="docutils literal notranslate"><span class="pre">prepare_batch</span></code>function defines the transformation from loaded
data to match the networks input and output shape and pushes everything
to the right device.</p>
</div>
</div>
<div class="section" id="abstract-networks-for-specific-backends">
<h2>Abstract Networks for specific Backends<a class="headerlink" href="#abstract-networks-for-specific-backends" title="Permalink to this headline">¶</a></h2>
<div class="section" id="pytorch">
<h3>PyTorch<a class="headerlink" href="#pytorch" title="Permalink to this headline">¶</a></h3>
<p>At the time of writing, PyTorch is the only backend which is supported,
but other backends are planned. In PyTorch every network should be
implemented as a subclass of <code class="docutils literal notranslate"><span class="pre">torch.nn.Module</span></code>, which also provides a
<code class="docutils literal notranslate"><span class="pre">__call__</span></code> method.</p>
<p>This results in sloghtly different requirements for PyTorch networks:
instead of implementing a <code class="docutils literal notranslate"><span class="pre">__call__</span></code> method, we simply call the
<code class="docutils literal notranslate"><span class="pre">torch.nn.Module.__call__</span></code> and therefore have to implement the
<code class="docutils literal notranslate"><span class="pre">forward</span></code> method, which defines the module’s behaviour and is
internally called by <code class="docutils literal notranslate"><span class="pre">torch.nn.Module.__call__</span></code> (among other stuff).
To give a default behaviour suiting most cases and not have to care
about internals, <code class="docutils literal notranslate"><span class="pre">delira</span></code> provides the <code class="docutils literal notranslate"><span class="pre">AbstractPyTorchNetwork</span></code>
which is a more specific case of the <code class="docutils literal notranslate"><span class="pre">AbstractNetwork</span></code> for PyTorch
modules.</p>
<div class="section" id="forward">
<h4><code class="docutils literal notranslate"><span class="pre">forward</span></code><a class="headerlink" href="#forward" title="Permalink to this headline">¶</a></h4>
<p>The <code class="docutils literal notranslate"><span class="pre">forward</span></code> function defines what has to be done to forward your
input through your network. Assuming your network has three
convolutional layers stored in <code class="docutils literal notranslate"><span class="pre">self.conv1</span></code>, <code class="docutils literal notranslate"><span class="pre">self.conv2</span></code> and
<code class="docutils literal notranslate"><span class="pre">self.conv3</span></code> and a ReLU stored in <code class="docutils literal notranslate"><span class="pre">self.relu</span></code>, a simple <code class="docutils literal notranslate"><span class="pre">forward</span></code>
function could look like this:</p>
<div class="code python highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_batch</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
    <span class="n">out_1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">input_batch</span><span class="p">))</span>
    <span class="n">out_2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">out_1</span><span class="p">))</span>
    <span class="n">out_3</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv3</span><span class="p">(</span><span class="n">out2</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">out_3</span>
</pre></div>
</div>
</div>
<div class="section" id="id1">
<h4><code class="docutils literal notranslate"><span class="pre">prepare_batch</span></code><a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h4>
<p>The default <code class="docutils literal notranslate"><span class="pre">prepare_batch</span></code> function for PyTorch networks looks like
this:</p>
<div class="code python highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nd">@staticmethod</span>
<span class="k">def</span> <span class="nf">prepare_batch</span><span class="p">(</span><span class="n">batch</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span> <span class="n">input_device</span><span class="p">,</span> <span class="n">output_device</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Helper Function to prepare Network Inputs and Labels (convert them to</span>
<span class="sd">    correct type and shape and push them to correct devices)</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    batch : dict</span>
<span class="sd">        dictionary containing all the data</span>
<span class="sd">    input_device : torch.device</span>
<span class="sd">        device for network inputs</span>
<span class="sd">    output_device : torch.device</span>
<span class="sd">        device for network outputs</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    dict</span>
<span class="sd">        dictionary containing data in correct type and shape and on correct</span>
<span class="sd">        device</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">return_dict</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;data&quot;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">batch</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;data&quot;</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span>
        <span class="n">input_device</span><span class="p">)}</span>

    <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">vals</span> <span class="ow">in</span> <span class="n">batch</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="n">return_dict</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">vals</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">output_device</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">return_dict</span>
</pre></div>
</div>
<p>and can be customized by subclassing the <code class="docutils literal notranslate"><span class="pre">AbstractPyTorchNetwork</span></code>.</p>
</div>
<div class="section" id="closure-example">
<h4><code class="docutils literal notranslate"><span class="pre">closure</span> <span class="pre">example</span></code><a class="headerlink" href="#closure-example" title="Permalink to this headline">¶</a></h4>
<p>A simple closure function for a PyTorch module could look like this:</p>
<div class="code python highlight-default notranslate"><div class="highlight"><pre><span></span>    @staticmethod
    def closure(model: AbstractPyTorchNetwork, data_dict: dict,
                optimizers: dict, criterions={}, metrics={},
                fold=0, **kwargs):
        &quot;&quot;&quot;
        closure method to do a single backpropagation step

        Parameters
        ----------
        model : :class:`ClassificationNetworkBasePyTorch`
            trainable model
        data_dict : dict
            dictionary containing the data
        optimizers : dict
            dictionary of optimizers to optimize model&#39;s parameters
        criterions : dict
            dict holding the criterions to calculate errors
            (gradients from different criterions will be accumulated)
        metrics : dict
            dict holding the metrics to calculate
        fold : int
            Current Fold in Crossvalidation (default: 0)
        **kwargs:
            additional keyword arguments

        Returns
        -------
        dict
            Metric values (with same keys as input dict metrics)
        dict
            Loss values (with same keys as input dict criterions)
        list
            Arbitrary number of predictions as torch.Tensor

        Raises
        ------
        AssertionError
            if optimizers or criterions are empty or the optimizers are not
            specified

        &quot;&quot;&quot;

        assert (optimizers and criterions) or not optimizers, \
            &quot;Criterion dict cannot be emtpy, if optimizers are passed&quot;

        loss_vals = {}
        metric_vals = {}
        total_loss = 0

        # choose suitable context manager:
        if optimizers:
            context_man = torch.enable_grad

        else:
            context_man = torch.no_grad

        with context_man():

            inputs = data_dict.pop(&quot;data&quot;)
            preds = model(inputs)

            if data_dict:

                for key, crit_fn in criterions.items():
                    _loss_val = crit_fn(preds, *data_dict.values())
                    loss_vals[key] = _loss_val.detach()
                    total_loss += _loss_val

                with torch.no_grad():
                    for key, metric_fn in metrics.items():
                        metric_vals[key] = metric_fn(
                            preds, *data_dict.values())

        if optimizers:
            optimizers[&#39;default&#39;].zero_grad()
            total_loss.backward()
            optimizers[&#39;default&#39;].step()

        else:

            # add prefix &quot;val&quot; in validation mode
            eval_loss_vals, eval_metrics_vals = {}, {}
            for key in loss_vals.keys():
                eval_loss_vals[&quot;val_&quot; + str(key)] = loss_vals[key]

            for key in metric_vals:
                eval_metrics_vals[&quot;val_&quot; + str(key)] = metric_vals[key]

            loss_vals = eval_loss_vals
            metric_vals = eval_metrics_vals

        for key, val in {**metric_vals, **loss_vals}.items():
            logging.info({&quot;value&quot;: {&quot;value&quot;: val.item(), &quot;name&quot;: key,
                                    &quot;env_appendix&quot;: &quot;_%02d&quot; % fold
                                    }})

        logging.info({&#39;image_grid&#39;: {&quot;images&quot;: inputs, &quot;name&quot;: &quot;input_images&quot;,
                                     &quot;env_appendix&quot;: &quot;_%02d&quot; % fold}})

        return metric_vals, loss_vals, [preds]

**Note:** This closure is taken from the
``delira.models.classification.ClassificationNetworkBasePyTorch``
</pre></div>
</div>
</div>
</div>
<div class="section" id="other-examples">
<h3>Other examples<a class="headerlink" href="#other-examples" title="Permalink to this headline">¶</a></h3>
<p>In <code class="docutils literal notranslate"><span class="pre">delira.models</span></code> you can find exemplaric implementations of
generative adversarial networks, classification and regression
approaches or segmentation networks.</p>
</div>
</div>
<div class="section" id="training">
<h2>Training<a class="headerlink" href="#training" title="Permalink to this headline">¶</a></h2>
<div class="section" id="parameters">
<h3>Parameters<a class="headerlink" href="#parameters" title="Permalink to this headline">¶</a></h3>
<p>Training-parameters (often called hyperparameters) can be defined in the
<code class="docutils literal notranslate"><span class="pre">delira.training.Parameters</span></code> class.</p>
<p>The class accepts the parameters <code class="docutils literal notranslate"><span class="pre">batch_size</span></code> and <code class="docutils literal notranslate"><span class="pre">num_epochs</span></code> to
define the batchsize and the number of epochs to train, the parameters
<code class="docutils literal notranslate"><span class="pre">optimizer_cls</span></code> and <code class="docutils literal notranslate"><span class="pre">optimizer_params</span></code> to create an optimizer or
training, the parameter <code class="docutils literal notranslate"><span class="pre">criterions</span></code> to specify the training
criterions (whose gradients will be accumulated by defaut), the
parameters <code class="docutils literal notranslate"><span class="pre">lr_sched_cls</span></code> and <code class="docutils literal notranslate"><span class="pre">lr_sched_params</span></code> to define the
learning rate scheduling and the parameter <code class="docutils literal notranslate"><span class="pre">metrics</span></code> to specify
evaluation metrics.</p>
<p>Additionally, it is possible to pass an aritrary number of keyword
arguments to the class</p>
<p>It is good practice to create a <code class="docutils literal notranslate"><span class="pre">Parameters</span></code> object at the beginning
and then use it for creating other objects which are needed for
training, since you can use the classes attributes and changes in
hyperparameters only have to be done once:</p>
<div class="code ipython3 highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">delira.training</span> <span class="k">import</span> <span class="n">Parameters</span>
<span class="kn">from</span> <span class="nn">delira.data_loading</span> <span class="k">import</span> <span class="n">RandomSampler</span><span class="p">,</span> <span class="n">SequentialSampler</span>

<span class="n">params</span> <span class="o">=</span> <span class="n">Parameters</span><span class="p">(</span><span class="n">fixed_params</span><span class="o">=</span><span class="p">{</span>
    <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="p">{},</span>
    <span class="s2">&quot;training&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">&quot;batch_size&quot;</span><span class="p">:</span> <span class="mi">64</span><span class="p">,</span> <span class="c1"># batchsize to use</span>
        <span class="s2">&quot;num_epochs&quot;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="c1"># number of epochs to train</span>
        <span class="s2">&quot;optimizer_cls&quot;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">,</span> <span class="c1"># optimization algorithm to use</span>
        <span class="s2">&quot;optimizer_params&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;lr&#39;</span><span class="p">:</span> <span class="mf">1e-3</span><span class="p">},</span> <span class="c1"># initialization parameters for this algorithm</span>
        <span class="s2">&quot;criterions&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;CE&quot;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()},</span> <span class="c1"># the loss function</span>
        <span class="s2">&quot;lr_sched_cls&quot;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>  <span class="c1"># the learning rate scheduling algorithm to use</span>
        <span class="s2">&quot;lr_sched_params&quot;</span><span class="p">:</span> <span class="p">{},</span> <span class="c1"># the corresponding initialization parameters</span>
        <span class="s2">&quot;metrics&quot;</span><span class="p">:</span> <span class="p">{}</span> <span class="c1"># and some evaluation metrics</span>
    <span class="p">}</span>
<span class="p">})</span>

<span class="c1"># recreating the data managers with the batchsize of the params object</span>
<span class="n">manager_train</span> <span class="o">=</span> <span class="n">BaseDataManager</span><span class="p">(</span><span class="n">dataset_train</span><span class="p">,</span> <span class="n">params</span><span class="o">.</span><span class="n">nested_get</span><span class="p">(</span><span class="s2">&quot;batch_size&quot;</span><span class="p">),</span> <span class="mi">1</span><span class="p">,</span>
                                <span class="n">transforms</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">sampler_cls</span><span class="o">=</span><span class="n">RandomSampler</span><span class="p">,</span>
                                <span class="n">n_process_loading</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="n">manager_val</span> <span class="o">=</span> <span class="n">BaseDataManager</span><span class="p">(</span><span class="n">dataset_val</span><span class="p">,</span> <span class="n">params</span><span class="o">.</span><span class="n">nested_get</span><span class="p">(</span><span class="s2">&quot;batch_size&quot;</span><span class="p">),</span> <span class="mi">3</span><span class="p">,</span>
                              <span class="n">transforms</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">sampler_cls</span><span class="o">=</span><span class="n">SequentialSampler</span><span class="p">,</span>
                              <span class="n">n_process_loading</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="trainer">
<h3>Trainer<a class="headerlink" href="#trainer" title="Permalink to this headline">¶</a></h3>
<p>The <code class="docutils literal notranslate"><span class="pre">delira.training.NetworkTrainer</span></code> class provides functions to train
a single network by passing attributes from your parameter object, a
<code class="docutils literal notranslate"><span class="pre">save_freq</span></code> to specify how often your model should be saved
(<code class="docutils literal notranslate"><span class="pre">save_freq=1</span></code> indicates every epoch, <code class="docutils literal notranslate"><span class="pre">save_freq=2</span></code> every second
epoch etc.) and <code class="docutils literal notranslate"><span class="pre">gpu_ids</span></code>. If you don’t pass any ids at all, your
network will be trained on CPU (and probably take a lot of time). If you
specify 1 id, the network will be trained on the GPU with the
corresponding index and if you pass multiple <code class="docutils literal notranslate"><span class="pre">gpu_ids</span></code> your network
will be trained on multiple GPUs in parallel.</p>
<blockquote>
<div><p><strong>Note:</strong> The GPU indices are refering to the devices listed in
<code class="docutils literal notranslate"><span class="pre">CUDA_VISIBLE_DEVICES</span></code>. E.g if <code class="docutils literal notranslate"><span class="pre">CUDA_VISIBLE_DEVICES</span></code> lists GPUs
3, 4, 5 then gpu_id 0 will be the index for GPU 3 etc.</p>
<p><strong>Note:</strong> training on multiple GPUs is not recommended for easy and
small networks, since for these networks the synchronization
overhead is far greater than the parallelization benefit.</p>
</div></blockquote>
<p>Training your network might look like this:</p>
<div class="code ipython3 highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">delira.training</span> <span class="k">import</span> <span class="n">PyTorchNetworkTrainer</span>
<span class="kn">from</span> <span class="nn">delira.models.classification</span> <span class="k">import</span> <span class="n">ClassificationNetworkBasePyTorch</span>

<span class="c1"># path where checkpoints should be saved</span>
<span class="n">save_path</span> <span class="o">=</span> <span class="s2">&quot;./results/checkpoints&quot;</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">ClassificationNetworkBasePyTorch</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_outputs</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>

<span class="n">trainer</span> <span class="o">=</span> <span class="n">PyTorchNetworkTrainer</span><span class="p">(</span><span class="n">network</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
                                <span class="n">save_path</span><span class="o">=</span><span class="n">save_path</span><span class="p">,</span>
                                <span class="n">criterions</span><span class="o">=</span><span class="n">params</span><span class="o">.</span><span class="n">nested_get</span><span class="p">(</span><span class="s2">&quot;criterions&quot;</span><span class="p">),</span>
                                <span class="n">optimizer_cls</span><span class="o">=</span><span class="n">params</span><span class="o">.</span><span class="n">nested_get</span><span class="p">(</span><span class="s2">&quot;optimizer_cls&quot;</span><span class="p">),</span>
                                <span class="n">optimizer_params</span><span class="o">=</span><span class="n">params</span><span class="o">.</span><span class="n">nested_get</span><span class="p">(</span><span class="s2">&quot;optimizer_params&quot;</span><span class="p">),</span>
                                <span class="n">metrics</span><span class="o">=</span><span class="n">params</span><span class="o">.</span><span class="n">nested_get</span><span class="p">(</span><span class="s2">&quot;metrics&quot;</span><span class="p">),</span>
                                <span class="n">lr_scheduler_cls</span><span class="o">=</span><span class="n">params</span><span class="o">.</span><span class="n">nested_get</span><span class="p">(</span><span class="s2">&quot;lr_sched_cls&quot;</span><span class="p">),</span>
                                <span class="n">lr_scheduler_params</span><span class="o">=</span><span class="n">params</span><span class="o">.</span><span class="n">nested_get</span><span class="p">(</span><span class="s2">&quot;lr_sched_params&quot;</span><span class="p">),</span>
                                <span class="n">gpu_ids</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                        <span class="p">)</span>

<span class="c1">#trainer.train(params.nested_get(&quot;num_epochs&quot;), manager_train, manager_val)</span>
</pre></div>
</div>
</div>
<div class="section" id="experiment">
<h3>Experiment<a class="headerlink" href="#experiment" title="Permalink to this headline">¶</a></h3>
<p>The <code class="docutils literal notranslate"><span class="pre">delira.training.AbstractExperiment</span></code> class needs an experiment
name, a path to save it’s results to, a parameter object, a model class
and the keyword arguments to create an instance of this class. It
provides methods to perform a single training and also a method for
running a kfold-cross validation. In order to create it, you must choose
the <code class="docutils literal notranslate"><span class="pre">PyTorchExperiment</span></code>, which is basically just a subclass of the
<code class="docutils literal notranslate"><span class="pre">AbstractExperiment</span></code> to provide a general setup for PyTorch modules.
Running an experiment could look like this:</p>
<div class="code ipython3 highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">delira.training</span> <span class="k">import</span> <span class="n">PyTorchExperiment</span>
<span class="kn">from</span> <span class="nn">delira.training.train_utils</span> <span class="k">import</span> <span class="n">create_optims_default_pytorch</span>

<span class="c1"># Add model parameters to Parameter class</span>
<span class="n">params</span><span class="o">.</span><span class="n">fixed</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;in_channels&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;n_outputs&quot;</span><span class="p">:</span> <span class="mi">10</span><span class="p">}</span>

<span class="n">experiment</span> <span class="o">=</span> <span class="n">PyTorchExperiment</span><span class="p">(</span><span class="n">params</span><span class="o">=</span><span class="n">params</span><span class="p">,</span>
                               <span class="n">model_cls</span><span class="o">=</span><span class="n">ClassificationNetworkBasePyTorch</span><span class="p">,</span>
                               <span class="n">name</span><span class="o">=</span><span class="s2">&quot;TestExperiment&quot;</span><span class="p">,</span>
                               <span class="n">save_path</span><span class="o">=</span><span class="s2">&quot;./results&quot;</span><span class="p">,</span>
                               <span class="n">optim_builder</span><span class="o">=</span><span class="n">create_optims_default_pytorch</span><span class="p">,</span>
                               <span class="n">gpu_ids</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

<span class="n">experiment</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">manager_train</span><span class="p">,</span> <span class="n">manager_val</span><span class="p">)</span>
</pre></div>
</div>
<p>An <code class="docutils literal notranslate"><span class="pre">Experiment</span></code> is the most abstract (and recommended) way to define,
train and validate your network.</p>
</div>
</div>
<div class="section" id="logging">
<h2>Logging<a class="headerlink" href="#logging" title="Permalink to this headline">¶</a></h2>
<p>Previous class and function definitions used pythons’s <code class="docutils literal notranslate"><span class="pre">logging</span></code>
library. As extensions for this library <code class="docutils literal notranslate"><span class="pre">delira</span></code> provides a package
(<code class="docutils literal notranslate"><span class="pre">delira.logging</span></code>) containing handlers to realize different logging
methods.</p>
<p>To use these handlers simply add them to your logger like this:</p>
<div class="code python highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">logger</span><span class="o">.</span><span class="n">addHandler</span><span class="p">(</span><span class="n">logging</span><span class="o">.</span><span class="n">StreamHandler</span><span class="p">())</span>
</pre></div>
</div>
<p>Nowadays, delira mainly relies on
<a class="reference external" href="https://github.com/MIC-DKFZ/trixi/">trixi</a> for logging and provides
only a <code class="docutils literal notranslate"><span class="pre">MultiStreamHandler</span></code> and a <code class="docutils literal notranslate"><span class="pre">TrixiHandler</span></code>, which is a binding
to <code class="docutils literal notranslate"><span class="pre">trixi</span></code>’s loggers and integrates them into the python <code class="docutils literal notranslate"><span class="pre">logging</span></code>
module</p>
<div class="section" id="multistreamhandler">
<h3><code class="docutils literal notranslate"><span class="pre">MultiStreamHandler</span></code><a class="headerlink" href="#multistreamhandler" title="Permalink to this headline">¶</a></h3>
<p>The <code class="docutils literal notranslate"><span class="pre">MultiStreamHandler</span></code> accepts an arbitrary number of streams during
initialization and writes the message to all of it’s streams during
logging.</p>
</div>
<div class="section" id="logging-with-visdom-the-trixi-loggers">
<h3>Logging with <code class="docutils literal notranslate"><span class="pre">Visdom</span></code> - The <code class="docutils literal notranslate"><span class="pre">trixi</span></code> Loggers<a class="headerlink" href="#logging-with-visdom-the-trixi-loggers" title="Permalink to this headline">¶</a></h3>
<p><code class="docutils literal notranslate"><span class="pre">`Visdom</span></code> &lt;<a class="reference external" href="https://github.com/facebookresearch/visdom">https://github.com/facebookresearch/visdom</a>&gt;`__ is a tool
designed to visualize your logs. To use this tool you need to open a
port on the machine you want to train on via
<code class="docutils literal notranslate"><span class="pre">visdom</span> <span class="pre">-port</span> <span class="pre">YOUR_PORTNUMBER</span></code> Afterwards just add the handler of your
choice to the logger. For more detailed information and customization
have a look at <a class="reference external" href="https://github.com/facebookresearch/visdom">this</a>
website.</p>
<p>Logging the scalar tensors containing <code class="docutils literal notranslate"><span class="pre">1</span></code>, <code class="docutils literal notranslate"><span class="pre">2</span></code>, <code class="docutils literal notranslate"><span class="pre">3</span></code>, <code class="docutils literal notranslate"><span class="pre">4</span></code> (at the
beginning; will increase to show epochwise logging) with the
corresponding keys <code class="docutils literal notranslate"><span class="pre">&quot;one&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">&quot;two&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">&quot;three&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">&quot;four&quot;</span></code> and two
random images with the keys <code class="docutils literal notranslate"><span class="pre">&quot;prediction&quot;</span></code> and <code class="docutils literal notranslate"><span class="pre">&quot;groundtruth&quot;</span></code> would
look like this:</p>
<div class="code ipython3 highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">NUM_ITERS</span> <span class="o">=</span> <span class="mi">4</span>

<span class="c1"># import logging handler and logging module</span>
<span class="kn">from</span> <span class="nn">delira.logging</span> <span class="k">import</span> <span class="n">TrixiHandler</span>
<span class="kn">from</span> <span class="nn">trixi.logger</span> <span class="k">import</span> <span class="n">PytorchVisdomLogger</span>
<span class="kn">import</span> <span class="nn">logging</span>

<span class="c1"># configure logging module (and root logger)</span>
<span class="n">logger_kwargs</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;name&#39;</span><span class="p">:</span> <span class="s1">&#39;test_env&#39;</span><span class="p">,</span> <span class="c1"># name of loggin environment</span>
    <span class="s1">&#39;port&#39;</span><span class="p">:</span> <span class="mi">9999</span> <span class="c1"># visdom port to connect to</span>
<span class="p">}</span>
<span class="n">logger_cls</span> <span class="o">=</span> <span class="n">PytorchVisdomLogger</span>

<span class="c1"># configure logging module (and root logger)</span>
<span class="n">logging</span><span class="o">.</span><span class="n">basicConfig</span><span class="p">(</span><span class="n">level</span><span class="o">=</span><span class="n">logging</span><span class="o">.</span><span class="n">INFO</span><span class="p">,</span>
                    <span class="n">handlers</span><span class="o">=</span><span class="p">[</span><span class="n">TrixiHandler</span><span class="p">(</span><span class="n">logger_cls</span><span class="p">,</span> <span class="o">**</span><span class="n">logger_kwargs</span><span class="p">)])</span>
<span class="c1"># derive logger from root logger</span>
<span class="c1"># (don&#39;t do `logger = logging.Logger(&quot;...&quot;)` since this will create a new</span>
<span class="c1"># logger which is unrelated to the root logger</span>
<span class="n">logger</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="s2">&quot;Test Logger&quot;</span><span class="p">)</span>

<span class="c1"># create dict containing the scalar numbers as torch.Tensor</span>
<span class="n">scalars</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;one&quot;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">]),</span>
           <span class="s2">&quot;two&quot;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="mi">2</span><span class="p">]),</span>
           <span class="s2">&quot;three&quot;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="mi">3</span><span class="p">]),</span>
           <span class="s2">&quot;four&quot;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="mi">4</span><span class="p">])}</span>

<span class="c1"># create dict containing the images as torch.Tensor</span>
<span class="c1"># pytorch awaits tensor dimensionality of</span>
<span class="c1"># batchsize x image channels x height x width</span>
<span class="n">images</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;prediction&quot;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">),</span>
          <span class="s2">&quot;groundtruth&quot;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">)}</span>

<span class="c1"># Simulate 4 Epochs</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="o">*</span><span class="n">NUM_ITERS</span><span class="p">):</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">({</span><span class="s2">&quot;image_grid&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;images&quot;</span><span class="p">:</span> <span class="n">images</span><span class="p">[</span><span class="s2">&quot;prediction&quot;</span><span class="p">],</span> <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;predictions&quot;</span><span class="p">}})</span>

    <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">val_tensor</span> <span class="ow">in</span> <span class="n">scalars</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">({</span><span class="s2">&quot;value&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;value&quot;</span><span class="p">:</span> <span class="n">val_tensor</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="n">key</span><span class="p">}})</span>
        <span class="n">scalars</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>

<span class="o">**</span><span class="n">Note</span><span class="p">:</span><span class="o">**</span> <span class="n">The</span> <span class="n">following</span> <span class="n">section</span> <span class="ow">is</span> <span class="n">deprecated</span> <span class="ow">and</span> <span class="ow">is</span> <span class="n">only</span> <span class="n">contained</span>
<span class="k">for</span> <span class="n">legacy</span> <span class="n">reasons</span><span class="o">.</span> <span class="n">It</span> <span class="ow">is</span> <span class="n">absolutely</span> <span class="ow">not</span> <span class="n">recommended</span> <span class="n">to</span> <span class="n">use</span> <span class="n">this</span>
<span class="n">code</span> <span class="c1">### ``ImgSaveHandler`` The ``ImgSaveHandler`` saves the images</span>
<span class="n">to</span> <span class="n">a</span> <span class="n">specified</span> <span class="n">directory</span><span class="o">.</span> <span class="n">The</span> <span class="n">logging</span> <span class="n">message</span> <span class="n">must</span> <span class="n">either</span> <span class="n">include</span> <span class="n">an</span>
<span class="n">image</span> <span class="ow">or</span> <span class="n">a</span> <span class="n">dictionary</span> <span class="n">containing</span> <span class="n">a</span> <span class="n">key</span> <span class="s1">&#39;images&#39;</span> <span class="n">which</span> <span class="n">should</span> <span class="n">be</span>
<span class="n">associated</span> <span class="k">with</span> <span class="n">a</span> <span class="nb">list</span> <span class="ow">or</span> <span class="nb">dict</span> <span class="n">of</span> <span class="n">images</span><span class="o">.</span>
</pre></div>
</div>
<div class="section" id="types-of-visdomhandlers">
<h4>Types of VisdomHandlers<a class="headerlink" href="#types-of-visdomhandlers" title="Permalink to this headline">¶</a></h4>
<p>The abilities of a handler is simply derivable by it’s name: A
<code class="docutils literal notranslate"><span class="pre">VisdomImageHandler</span></code> is the pure visdom logger, whereas the
<code class="docutils literal notranslate"><span class="pre">VisdomImageSaveHandler</span></code> combines the abilities of a
<code class="docutils literal notranslate"><span class="pre">VisdomImageHandler</span></code>and a <code class="docutils literal notranslate"><span class="pre">ImgSaveHandler</span></code>. Together with a
<code class="docutils literal notranslate"><span class="pre">StreamHandler</span></code> (in-built handler) you get the
<code class="docutils literal notranslate"><span class="pre">VisdomImageStreamHandler</span></code> and if you also want to add the option to
save images to disk, you should use the <code class="docutils literal notranslate"><span class="pre">VisdomImageSaveStreamHandler</span></code></p>
<p>The provided handlers are:</p>
<ul class="simple">
<li><code class="docutils literal notranslate"><span class="pre">ImgSaveHandler</span></code></li>
<li><code class="docutils literal notranslate"><span class="pre">MultistreamHandler</span></code></li>
<li><code class="docutils literal notranslate"><span class="pre">VisdomImageHandler</span></code></li>
<li><code class="docutils literal notranslate"><span class="pre">VisdomImageSaveHandler</span></code></li>
<li><code class="docutils literal notranslate"><span class="pre">VisdomImageSaveStreamHandler</span></code></li>
<li><code class="docutils literal notranslate"><span class="pre">VisdomStreamHandler</span></code></li>
</ul>
</div>
</div>
</div>
<div class="section" id="more-examples">
<h2>More Examples<a class="headerlink" href="#more-examples" title="Permalink to this headline">¶</a></h2>
<p>More Examples can be found in * <a class="reference external" href="classification_pytorch.ipynb,">the classification
example</a> * <a class="reference external" href="segmentation_2d_pytorch.ipynb,">the 2d segmentation
example</a> * <a class="reference external" href="segmentation_3d_pytorch.ipynb,">the 3d segmentation
example</a> * <a class="reference external" href="gan_pytorch.ipynb,">the generative
adversarial example</a></p>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="classification_pytorch.html" class="btn btn-neutral float-right" title="Classification with Delira - A very short introduction" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="getting_started.html" class="btn btn-neutral float-left" title="Getting started" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2019, Justus Schock, Oliver Rippel, Christoph Haarburger

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>